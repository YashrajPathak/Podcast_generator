import os, sys, re, wave, json, tempfile, asyncio, datetime, random, atexit, time
from pathlib import Path
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv; load_dotenv()

# ------------------------- temp tracking & cleanup -------------------------
TMP: List[str] = []
@atexit.register
def _cleanup():
    for p in TMP:
        try:
            if os.path.exists(p):
                os.remove(p)
        except Exception:
            pass

# ------------------------- Azure OpenAI (safe) -----------------------------
from openai import AzureOpenAI, BadRequestError
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")

if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def ensure_complete_sentence(text: str) -> str:
    """Ensure the response is a complete sentence without artificial truncation"""
    t = re.sub(r'[`*_#>]+', ' ', text or '').strip()
    t = re.sub(r'\s{2,}', ' ', t)
    if t and t[-1] not in {'.', '!', '?'}:
        t += '.'
    return t

def _llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
        max_tokens=max_tokens,
        temperature=temperature
    )
    return (r.choices[0].message.content or "").strip()

def _soften(text: str) -> str:
    t = text or ""
    t = re.sub(r'\b[Ss]ole factual source\b', 'primary context', t)
    t = re.sub(r'\b[Dd]o not\b', 'please avoid', t)
    t = re.sub(r"\b[Dd]on't\b", 'please avoid', t)
    t = re.sub(r'\b[Ii]gnore\b', 'do not rely on', t)
    t = t.replace("debate", "discussion").replace("Debate", "Discussion")
    return t

def _looks_ok(text: str) -> bool:
    return bool(text and len(text.strip()) >= 8 and text.count(".") <= 3 and not text.isupper() and not re.search(r'http[s]?://', text))

def llm_safe(system: str, user: str, max_tokens: int, temperature: float) -> str:
    try:
        out = _llm_sync(system, user, max_tokens, temperature)
        if not _looks_ok(out):
            out = _llm_sync(system, user, max_tokens=max(80, max_tokens//2), temperature=min(0.8, temperature+0.1))
        return ensure_complete_sentence(out)
    except BadRequestError:
        soft_sys = _soften(system) + " Always keep a professional, neutral tone and comply with safety policies."
        soft_user = _soften(user)
        try:
            out = _llm_sync(soft_sys, soft_user, max_tokens=max(80, max_tokens-20), temperature=max(0.1, temperature-0.2))
            return ensure_complete_sentence(out)
        except Exception:
            minimal_system = "You are a professional analyst; produce one safe, neutral sentence grounded in the provided context."
            minimal_user = "Summarize cross-metric trends and propose one action in a single safe sentence."
            out = _llm_sync(minimal_system, minimal_user, max_tokens=100, temperature=0.2)
            return ensure_complete_sentence(out)

async def llm(system: str, user: str, max_tokens: int = 130, temperature: float = 0.45) -> str:
    return await asyncio.to_thread(llm_safe, system, user, max_tokens, temperature)

# ------------------------- Azure Speech (AAD) ------------------------------
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID = os.getenv("TENANT_ID")
CLIENT_ID = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION", "eastus")
RESOURCE_ID = os.getenv("RESOURCE_ID")
COG_SCOPE = "https://cognitiveservices.azure.com/.default"

if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)

def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

VOICE_NEXUS = os.getenv("AZURE_VOICE_HOST", "en-US-SaraNeural")
VOICE_RECO  = os.getenv("AZURE_VOICE_BA",   "en-US-JennyNeural")
VOICE_STAT  = os.getenv("AZURE_VOICE_DA",   "en-US-BrianNeural")

VOICE_PLAN = {
    "NEXUS": {"style": "friendly", "base_pitch": "+1%", "base_rate": "-2%"},
    "RECO":  {"style": "cheerful", "base_pitch": "+2%", "base_rate": "-3%"},
    "STAT":  {"style": "serious",  "base_pitch": "-1%", "base_rate": "-4%"},
}

def _jitter(pct: str, spread=3) -> str:
    m = re.match(r'([+-]?\d+)%', pct.strip())
    base = int(m.group(1)) if m else 0
    j = random.randint(-spread, spread)
    return f"{base+j}%"

def _emphasize_numbers(text: str) -> str:
    wrap = lambda s: f'<emphasis level="moderate">{s}</emphasis>'
    t = re.sub(r'\b\d{3,}(\.\d+)?\b', lambda m: wrap(m.group(0)), text)
    t = re.sub(r'\b-?\d+(\.\d+)?%\b', lambda m: wrap(m.group(0)), t)
    return t

def _clause_pauses(text: str) -> str:
    t = re.sub(r',\s', ',<break time="220ms"/> ', text)
    t = re.sub(r';\s', ';<break time="260ms"/> ', t)
    t = re.sub(r'\bHowever\b', 'However,<break time="220ms"/>', t, flags=re.I)
    t = re.sub(r'\bBut\b',     'But,<break time="220ms"/>',     t, flags=re.I)
    return t

def _inflect(text: str, role: str) -> tuple[str, str]:
    base_pitch = VOICE_PLAN[role]["base_pitch"]
    base_rate  = VOICE_PLAN[role]["base_rate"]
    pitch = _jitter(base_pitch, 3)
    rate  = _jitter(base_rate,  2)
    if text.strip().endswith("?"):
        try: pitch = f"{int(pitch.replace('%',''))+4}%"
        except: pitch = "+4%"
    elif re.search(r'\bhowever\b|\bbut\b', text, re.I):
        try: pitch = f"{int(pitch.replace('%',''))-2}%"
        except: pitch = "-2%"
    elif any(w in text.lower() for w in ['surprising','shocking','unexpected','dramatic']):
        try: pitch = f"{int(pitch.replace('%',''))+3}%"
        except: pitch = "+3%"
    return pitch, rate

def _ssml(voice: str, style: Optional[str], rate: str, pitch: str, inner: str) -> str:
    if style:
        return f"""<speak version="1.0" xml:lang="en-US" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts">
<voice name="{voice}"><mstts:express-as style="{style}"><prosody rate="{rate}" pitch="{pitch}">{inner}</prosody></mstts:express-as></voice>
</speak>"""
    return f"""<speak version="1.0" xml:lang="en-US" xmlns="http://www.w3.org/2001/10/synthesis">
<voice name="{voice}"><prosody rate="{rate}" pitch="{pitch}">{inner}</prosody></voice>
</speak>"""

def text_to_ssml(text: str, role: str) -> str:
    plan = VOICE_PLAN[role]
    t = _emphasize_numbers(text.strip())
    t = _clause_pauses(t)
    t = f'{t}<break time="320ms"/>'
    pitch, rate = _inflect(text, role)
    voice = VOICE_NEXUS if role == "NEXUS" else VOICE_RECO if role == "RECO" else VOICE_STAT
    return _ssml(voice, plan["style"], rate, pitch, t)

def synth(ssml: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)
    fd, tmp = tempfile.mkstemp(prefix="seg_", suffix=".wav"); os.close(fd)
    TMP.append(tmp)
    out = speechsdk.audio.AudioOutputConfig(filename=tmp)
    spk = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=out)
    r = spk.speak_ssml_async(ssml).get()
    if r.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp
    # fallback once
    plain = re.sub(r'<[^>]+>', ' ', ssml)
    r = spk.speak_text_async(plain).get()
    if r.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp
    try: os.remove(tmp)
    except: pass
    raise RuntimeError("TTS failed")

def wav_len(path: str) -> float:
    with wave.open(path, "rb") as r:
        fr = r.getframerate() or 24000
        return r.getnframes() / float(fr)

def write_master(segments: List[str], out_path: str, rate=24000) -> str:
    fd, tmp = tempfile.mkstemp(prefix="final_", suffix=".wav"); os.close(fd)
    try:
        with wave.open(tmp, "wb") as w:
            w.setnchannels(1); w.setsampwidth(2); w.setframerate(rate)
            for seg in segments:
                with wave.open(seg, "rb") as r:
                    if (r.getframerate(), r.getnchannels(), r.getsampwidth()) != (rate, 1, 2):
                        raise RuntimeError(f"Segment format mismatch: {seg}")
                    w.writeframes(r.readframes(r.getnframes()))
        try:
            os.replace(tmp, out_path)
        except PermissionError:
            base, ext = os.path.splitext(out_path)
            alt = f"{base}{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}{ext}"
            os.replace(tmp, alt)
            print(f"⚠️ Output was locked; wrote to {alt}")
            return alt
        return out_path
    except Exception:
        try: os.remove(tmp)
        except: pass
        raise

# ------------------------- file selection & context ------------------------
def list_json_files() -> List[str]:
    return [p.name for p in Path(".").iterdir() if p.is_file() and p.suffix.lower() == ".json"]

def ask_files() -> str:
    files = list_json_files()
    print("JSON files in folder:", files)
    print("Type one of: data.json, metric_data.json, both, then Enter:")
    choice = (sys.stdin.readline() or "").strip().lower()
    if choice not in {"data.json", "metric_data.json", "both"}:
        if "data.json" in files and "metric_data.json" in files:
            return "both"
        return files[0] if files else "both"
    return choice

def load_context(choice: str) -> tuple[str, dict]:
    ctx, meta = "", {"files": []}
    def add(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    if choice == "both":
        ctx += add("data.json") + add("metric_data.json")
    else:
        ctx += add(choice)
    if not ctx:
        raise RuntimeError("No data found (need data.json and/or metric_data.json).")
    return ctx, meta

def ask_turns_and_duration() -> tuple[int, float]:
    print("Enter desired number of Reco/Stat turns (each turn = Reco then Stat). Press Enter for default 6:")
    t = (sys.stdin.readline() or "").strip()
    try: turns = int(t) if t else 6
    except: turns = 6
    turns = max(4, min(12, turns))
    print("Enter desired duration in minutes (2–5). Press Enter for default 3:")
    m = (sys.stdin.readline() or "").strip()
    try: mins = float(m) if m else 3.0
    except: mins = 3.0
    mins = max(2.0, min(5.0, mins))
    return turns, mins * 60.0

# ------------------------- prompts ----------------------------------------
SYSTEM_NEXUS = "You are Agent Nexus, the host. Keep it concise, warm, and professional."
SYSTEM_RECO  = "You are Agent Reco, the recommendation specialist; be concrete and actionable."
SYSTEM_STAT  = "You are Agent Stat, the integrity expert; be cautious, precise, and practical."

NEXUS_INTRO = ("Hello and welcome to Optum MultiAgent Conversation, where intelligence meets collaboration. "
               "I'm Agent Nexus, your host and guide through today's episode.")
RECO_INTRO  = ("Hi everyone, I'm Agent Reco, your go-to for metric recommendations. "
               "I specialize in identifying the most impactful metrics for performance tracking and optimization.")
STAT_INTRO  = ("Hello! I'm Agent Stat, focused on metric data integrity. "
               "I ensure our metrics are not just smart, but solid and reliable.")
NEXUS_OUTRO = ("And that brings us to the end of today's episode of Optum MultiAgent Conversation. "
               "Thank you to our experts and thank you for tuning in. Stay curious, stay data-driven!")

async def generate_nexus_topic_intro(context: str) -> str:
    user = f"Given this data context, introduce 2–3 key talking points for the show in 2 sentences:\n{context[:6000]}"
    return await llm(SYSTEM_NEXUS, user, max_tokens=120, temperature=0.4)

# ------------------------- conversation run -------------------------------
async def run_podcast_cli():
    print("Starting Optum MultiAgent Conversation Podcast Generator (no music)…")
    choice = ask_files()
    context, meta = load_context(choice)
    turns, target_seconds = ask_turns_and_duration()

    # opening lines
    segments: List[str] = []
    convo: List[Dict[str, str]] = []

    # Nexus intro
    seg = synth(text_to_ssml(NEXUS_INTRO, "NEXUS")); segments.append(seg); convo.append({"speaker":"NEXUS","text":NEXUS_INTRO})
    # Reco intro
    seg = synth(text_to_ssml(RECO_INTRO, "RECO"));   segments.append(seg); convo.append({"speaker":"RECO","text":RECO_INTRO})
    # Stat intro
    seg = synth(text_to_ssml(STAT_INTRO, "STAT"));   segments.append(seg); convo.append({"speaker":"STAT","text":STAT_INTRO})

    # Topic intro
    topic_intro = await generate_nexus_topic_intro(context)
    seg = synth(text_to_ssml(topic_intro, "NEXUS")); segments.append(seg); convo.append({"speaker":"NEXUS","text":topic_intro})

    # turns
    last_stat_line = ""
    last_reco_line = ""
    for i in range(turns):
        # Reco
        r_user = f"Context:\n{context[:6000]}\nRespond to Stat: '{last_stat_line}' in one concise sentence with one concrete recommendation."
        reco_line = await llm(SYSTEM_RECO, r_user, max_tokens=120, temperature=0.45)
        seg = synth(text_to_ssml(reco_line, "RECO")); segments.append(seg); convo.append({"speaker":"RECO","text":reco_line})
        last_reco_line = reco_line

        # Stat
        s_user = f"Context:\n{context[:6000]}\nRespond to Reco: '{last_reco_line}' in one concise sentence with one concrete validation or risk check."
        stat_line = await llm(SYSTEM_STAT, s_user, max_tokens=120, temperature=0.45)
        seg = synth(text_to_ssml(stat_line, "STAT")); segments.append(seg); convo.append({"speaker":"STAT","text":stat_line})
        last_stat_line = stat_line

    # outro
    seg = synth(text_to_ssml(NEXUS_OUTRO, "NEXUS")); segments.append(seg); convo.append({"speaker":"NEXUS","text":NEXUS_OUTRO})

    # write outputs
    out_wav = f"podcast_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
    write_master(segments, out_wav)
    out_json = out_wav.replace(".wav", ".json")
    Path(out_json).write_text(json.dumps({"conversation":convo,"files_used":meta.get("files",[])}, indent=2), encoding="utf-8")

    dur = sum(wav_len(p) for p in segments)
    print("\n--- DONE ---")
    print(f"Final audio: {out_wav}")
    print(f"Conversation log: {out_json}")
    print(f"Approx duration: {dur:.1f}s")

# ------------------------- FastAPI Server (optional) ----------------------
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn

app = FastAPI()

class GenerateRequest(BaseModel):
    system_prompt: str
    user_prompt: str
    max_tokens: int = 150
    temperature: float = 0.45

class AudioRequest(BaseModel):
    text: str
    voice: str

@app.post("/generate-response")
async def generate_response(request: GenerateRequest):
    try:
        response = await llm(request.system_prompt, request.user_prompt, request.max_tokens, request.temperature)
        return {"text": response, "success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate-audio")
async def generate_audio_endpoint(request: AudioRequest):
    try:
        ssml = text_to_ssml(request.text, request.voice)
        audio_file = synth(ssml)
        return {"audio_path": audio_file, "success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "podcast-engine", "port": 8001}

# ------------------------- entry ------------------------------------------
if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "serve":
        uvicorn.run(app, host="0.0.0.0", port=8001, reload=True)
    else:
        try:
            asyncio.run(run_podcast_cli())
        except Exception as e:
            print(f"X Error: {e}")
            import traceback; traceback.print_exc()
