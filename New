import os, sys, re, wave, json, tempfile, asyncio, datetime, random, atexit, time
from pathlib import Path
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv; load_dotenv()

# ------------------------- temp tracking & cleanup -------------------------
TMP: list[str] = []
@atexit.register
def _cleanup():
    for p in TMP:
        try:
            if os.path.exists(p):
                os.remove(p)
        except Exception:
            pass

# ------------------------- Azure OpenAI (safe) -----------------------------
from openai import AzureOpenAI, BadRequestError
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")

if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def _llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
        max_tokens=max_tokens,
        temperature=temperature
    )
    return (r.choices[0].message.content or "").strip()

def _soften(text: str) -> str:
    t = text
    t = re.sub(r'\b[Ss]ole factual source\b', 'primary context', t)
    t = re.sub(r'\b[Dd]o not\b', 'please avoid', t)
    t = re.sub(r"\b[Dd]on't\b", 'please avoid', t)
    t = re.sub(r'\b[Ii]gnore\b', 'do not rely on', t)
    t = t.replace("debate", "discussion").replace("Debate", "Discussion")
    return t

def ensure_complete_sentence(text: str) -> str:
    """Ensure the response is a complete sentence without artificial truncation"""
    t = re.sub(r'[`*_#>]+', ' ', text).strip()
    t = re.sub(r'\s{2,}', ' ', t)
    if t and t[-1] not in {'.', '!', '?'}:
        t += '.'
    return t

def _looks_ok(text: str) -> bool:
    return bool(text and len(text.strip()) >= 8 and text.count(".") <= 3 and not text.isupper() and not re.search(r'http[s]?://', text))

def llm_safe(system: str, user: str, max_tokens: int, temperature: float) -> str:
    try:
        out = _llm_sync(system, user, max_tokens, temperature)
        if not _looks_ok(out):
            out = _llm_sync(system, user, max_tokens=max(80, max_tokens//2), temperature=min(0.8, temperature+0.1))
        return ensure_complete_sentence(out)
    except BadRequestError:
        soft_sys = _soften(system) + " Always keep a professional, neutral tone and comply with safety policies."
        soft_user = _soften(user)
        try:
            out = _llm_sync(soft_sys, soft_user, max_tokens=max(80, max_tokens-20), temperature=max(0.1, temperature-0.2))
            return ensure_complete_sentence(out)
        except Exception:
            minimal_system = "You are a professional analyst; produce one safe, neutral sentence grounded in the provided context."
            minimal_user = "Summarize cross-metric trends and propose one action in a single safe sentence."
            out = _llm_sync(minimal_system, minimal_user, max_tokens=100, temperature=0.2)
            return ensure_complete_sentence(out)

async def llm(system: str, user: str, max_tokens: int = 130, temperature: float = 0.45) -> str:
    return await asyncio.to_thread(llm_safe, system, user, max_tokens, temperature)

# ------------------------- Azure Speech (AAD) ------------------------------
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID = os.getenv("TENANT_ID")
CLIENT_ID = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION", "eastus")
RESOURCE_ID = os.getenv("RESOURCE_ID")
COG_SCOPE = "https://cognitiveservices.azure.com/.default"

if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)

def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

# ---- Voices
VOICE_NEXUS = os.getenv("AZURE_VOICE_HOST", "en-US-SaraNeural")
VOICE_RECO  = os.getenv("AZURE_VOICE_BA",   "en-US-JennyNeural")
VOICE_STAT  = os.getenv("AZURE_VOICE_DA",   "en-US-BrianNeural")

VOICE_PLAN = {
    "NEXUS": {"style": "friendly", "base_pitch": "+1%", "base_rate": "-2%"},
    "RECO":  {"style": "cheerful", "base_pitch": "+2%", "base_rate": "-3%"},
    "STAT":  {"style": "serious",  "base_pitch": "-1%", "base_rate": "-4%"},
}

def _jitter(pct: str, spread=3) -> str:
    m = re.match(r'([+-]?\d+)%', pct.strip())
    base = int(m.group(1)) if m else 0
    j = random.randint(-spread, spread)
    return f"{base+j}%"

def _emphasize_numbers(text: str) -> str:
    wrap = lambda s: f'<emphasis level="moderate">{s}</emphasis>'
    t = re.sub(r'\b\d{3,}(\.\d+)?\b', lambda m: wrap(m.group(0)), text)
    t = re.sub(r'\b-?\d+(\.\d+)?%\b', lambda m: wrap(m.group(0)), t)
    return t

def _clause_pauses(text: str) -> str:
    t = re.sub(r',\s', ',<break time="220ms"/> ', text)
    t = re.sub(r';\s', ';<break time="260ms"/> ', t)
    t = re.sub(r'\bHowever\b', 'However,<break time="220ms"/>', t, flags=re.I)
    t = re.sub(r'\bBut\b', 'But,<break time="220ms"/>', t, flags=re.I)
    return t

def _inflect(text: str, role: str) -> tuple[str, str]:
    base_pitch = VOICE_PLAN[role]["base_pitch"]
    base_rate = VOICE_PLAN[role]["base_rate"]
    pitch = _jitter(base_pitch, 3)
    rate  = _jitter(base_rate, 2)
    if text.strip().endswith("?"):
        try:
            p = int(pitch.replace('%', '')); pitch = f"{p+4}%"
        except:
            pitch = "+4%"
    elif re.search(r'\bhowever\b|\bbut\b', text, re.I):
        try:
            p = int(pitch.replace('%', '')); pitch = f"{p-2}%"
        except:
            pitch = "-2%"
    elif any(w in text.lower() for w in ['surprising','shocking','unexpected','dramatic']):
        try:
            p = int(pitch.replace('%', '')); pitch = f"{p+3}%"
        except:
            pitch = "+3%"
    return pitch, rate

def _ssml(voice: str, style: str | None, rate: str, pitch: str, inner: str) -> str:
    if style:
        return f"""<speak version="1.0" xml:lang="en-US" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts">
    <voice name="{voice}">
        <mstts:express-as style="{style}">
            <prosody rate="{rate}" pitch="{pitch}">{inner}</prosody>
        </mstts:express-as>
    </voice>
</speak>"""
    else:
        return f"""<speak version="1.0" xml:lang="en-US" xmlns="http://www.w3.org/2001/10/synthesis">
    <voice name="{voice}">
        <prosody rate="{rate}" pitch="{pitch}">{inner}</prosody>
    </voice>
</speak>"""

def text_to_ssml(text: str, role: str) -> str:
    plan = VOICE_PLAN[role]
    t = _emphasize_numbers(text.strip())
    t = _clause_pauses(t)
    t = f'{t}<break time="320ms"/>'
    pitch, rate = _inflect(text, role)
    voice = VOICE_NEXUS if role == "NEXUS" else VOICE_RECO if role == "RECO" else VOICE_STAT
    return _ssml(voice, plan["style"], rate, pitch, t)

def synth(ssml: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)
    fd, tmp = tempfile.mkstemp(prefix="seg_", suffix=".wav")
    os.close(fd)
    TMP.append(tmp)
    out = speechsdk.audio.AudioOutputConfig(filename=tmp)
    spk = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=out)
    r = spk.speak_ssml_async(ssml).get()
    if r.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp
    # fallback once
    plain = re.sub(r'<[^>]+>', ' ', ssml)
    spk = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=out)
    r = spk.speak_text_async(plain).get()
    if r.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp
    try:
        os.remove(tmp)
    except:
        pass
    raise RuntimeError("TTS failed")

def wav_len(path: str) -> float:
    with wave.open(path, "rb") as r:
        fr = r.getframerate() or 24000
        return r.getnframes() / float(fr)

def write_master(segments: list[str], out_path: str, rate=24000) -> str:
    fd, tmp = tempfile.mkstemp(prefix="final_", suffix=".wav")
    os.close(fd)
    try:
        with wave.open(tmp, "wb") as w:
            w.setnchannels(1)
            w.setsampwidth(2)
            w.setframerate(rate)
            for seg in segments:
                with wave.open(seg, "rb") as r:
                    if (r.getframerate(), r.getnchannels(), r.getsampwidth()) != (rate, 1, 2):
                        raise RuntimeError(f"Segment format mismatch: {seg}")
                    w.writeframes(r.readframes(r.getnframes()))
        try:
            os.replace(tmp, out_path)
        except PermissionError:
            base, ext = os.path.splitext(out_path)
            alt = f"{base}{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}{ext}"
            os.replace(tmp, alt)
            print(f"⚠️ Output was locked; wrote to {alt}")
            return alt
        return out_path
    except Exception:
        try:
            os.remove(tmp)
        except:
            pass
        raise

# ------------------------- file selection & context ------------------------
def list_json_files() -> list[str]:
    return [p.name for p in Path(".").iterdir() if p.is_file() and p.suffix.lower() == ".json"]

def ask_files() -> str:
    files = list_json_files()
    print("JSON files in folder:", files)
    print("Type one of: data.json, metric_data.json, both, then Enter:")
    choice = (sys.stdin.readline() or "").strip().lower()
    if choice not in {"data.json", "metric_data.json", "both"}:
        if "data.json" in files and "metric_data.json" in files:
            return "both"
        return files[0] if files else "both"
    return choice

def load_context(choice: str) -> tuple[str, dict]:
    ctx, meta = "", {"files": []}
    def add(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    if choice == "both":
        ctx += add("data.json") + add("metric_data.json")
    else:
        ctx += add(choice)
    if not ctx:
        raise RuntimeError("No data found (need data.json and/or metric_data.json).")
    return ctx, meta

def ask_turns_and_duration() -> tuple[int, float]:
    print("Enter desired number of Reco/Stat turns (each turn = Reco then Stat). Press Enter for default 6:")
    t = (sys.stdin.readline() or "").strip()
    try:
        turns = int(t) if t else 6
    except:
        turns = 6
    turns = max(4, min(12, turns))
    print("Enter desired duration in minutes (2–5). Press Enter for default 3:")
    m = (sys.stdin.readline() or "").strip()
    try:
        mins = float(m) if m else 3.0
    except:
        mins = 3.0
    mins = max(2.0, min(5.0, mins))
    return turns, mins * 60.0

# ------------------------- opener control / humanization -------------------
FORBIDDEN = {
    "RECO": {"absolutely","well","look","sure","okay","so","listen","hey","you know","hold on","right","great point"},
    "STAT": {"hold on","actually","well","look","so","right","okay","absolutely","you know","listen","wait"},
}

OPENERS = {
    "RECO": [
        "Given that","Looking at this","From that signal","On those figures",
        "Based on the last month","If we take the trend","Against YTD context","From a planning view"
    ],
    "STAT": [
        "Data suggests","From the integrity check","The safer interpretation","Statistically speaking",
        "Given the variance profile","From the control limits","Relative to seasonality","From the timestamp audit"
    ],
}

def strip_forbidden(text: str, role: str) -> str:
    low = text.strip().lower()
    for w in sorted(FORBIDDEN[role], key=lambda x: -len(x)):
        if low.startswith(w + " ") or low == w:
            return text[len(w):].lstrip(" ,.-–—")
    return text

def vary_opening(text: str, role: str, last_open: dict) -> str:
    t = strip_forbidden(text, role)
    first = (t.split()[:1] or [""])[0].strip(",. ").lower()
    if first in FORBIDDEN[role] or not first or random.random() < 0.4:
        cand = random.choice(OPENERS[role])
        if last_open.get(role) == cand:
            pool = [c for c in OPENERS[role] if c != cand]
            cand = random.choice(pool) if pool else cand
        last_open[role] = cand
        return f"{cand}, {t}"
    return t

def ensure_complete_response_line(text: str) -> str:
    text = text.strip()
    if text and text[-1] not in {'.','!','?'}:
        text += '.'
    return text

# ------------------------ Conversation Dynamics ----------------------------
INTERRUPTION_CHANCE = 0.25
AGREE_DISAGREE_RATIO = 0.6

def _add_conversation_dynamics(text: str, role: str, last_speaker: str, context: str, turn_count: int, conversation_history: list) -> str:
    other_agent = "Stat" if role == "RECO" else "Reco" if role == "STAT" else ""
    added_element = False
    should_use_name = (
        any(w in text.lower() for w in ['important','crucial','critical','significant','essential']) or
        any(w in text.lower() for w in ['but','however','although','disagree','challenge','contrary']) or
        (turn_count > 2 and random.random() < 0.3) or
        any(w in text.lower() for w in ['surprising','shocking','unexpected','dramatic','remarkable']) or
        (len(conversation_history) > 2 and "alternative" in text.lower()) or
        (random.random() < 0.2 and any(w in text.lower() for w in ['agree','right','correct','valid']))
    )
    if other_agent and should_use_name and random.random() < 0.7 and not added_element:
        text = f"{other_agent}, {text.lower()}"
        added_element = True
    if not added_element and random.random() < 0.25 and any(w in text.lower() for w in ['surprising','shocking','unexpected','dramatic','remarkable','concerning']):
        text = f"{random.choice(['Surprisingly, ','Interestingly, ','Remarkably, ','Unexpectedly, '])}{text}"
        added_element = True
    if not added_element and random.random() < INTERRUPTION_CHANCE and role != "NEXUS" and last_speaker and turn_count > 1:
        if random.random() < 0.5:
            text = f"{random.choice(['I see what you\'re saying, ','That\'s a good point, ','I understand your perspective, ','You make a valid observation, '])}{text.lower()}"
        else:
            text = f"{random.choice(['If I might add, ','Building on that, ','To expand on your point, ','Another way to look at this is '])}{text}"
        added_element = True
    if not added_element and random.random() < 0.35 and role != "NEXUS" and turn_count > 1:
        if random.random() < AGREE_DISAGREE_RATIO:
            text = f"{random.choice(['I agree with that approach, ','That makes sense, ','You\'re right about that, ','That\'s a solid recommendation, '])}{text.lower()}"
        else:
            text = f"{random.choice(['I have a slightly different view, ','Another perspective to consider, ','We might approach this differently, ','Let me offer an alternative take, '])}{text.lower()}"
    # de-dupe
    text = re.sub(r'\b(Reco|Stat),\s+\1,?\s+', r'\1, ', text)
    text = re.sub(r'\b(\w+)\s+\1\b', r'\1', text)
    return text

# ------------------------- AGENT PROMPTS (characters) ----------------------
SYSTEM_RECO = (
    "ROLE & PERSONA: You are Agent Reco, a senior metrics recommendation specialist. "
    "You advise leaders on which metrics matter, how to monitor them, and what actions to take. "
    "Voice: confident, concise, consultative, human; fast back-and-forth with Agent Stat.\n\n"
    "CONSTRAINTS:\n"
    "• Complete sentences (≈15–30 words). Plain text only. "
    "• Respond directly to Stat’s last point and add one actionable recommendation. "
    "• Include one concrete method (rolling average, control chart, seasonality check, cohort analysis, anomaly band, validation). "
    "• Vary openers; avoid fillers. Use numbers from context when helpful, never invent values. "
    "• One idea per sentence; be crisp.\n\n"
    "OUTPUT: one complete sentence tied to Stat’s last line, ending with a clear recommendation."
)

SYSTEM_STAT = (
    "ROLE & PERSONA: You are Agent Stat, the data integrity and statistical rigor partner. "
    "You validate assumptions, challenge leaps, and anchor decisions in measurement quality and trend mechanics. "
    "Voice: thoughtful, precise, collaborative skeptic.\n\n"
    "CONSTRAINTS:\n"
    "• Complete sentences (≈15–30 words). Plain text only. "
    "• Reply explicitly to Reco—agree, qualify, or refute—and add one concrete check or risk. "
    "• Prefer checks like stationarity, seasonal decomposition, control charts, cohort splits, anomaly bands, key/Timezone validation. "
    "• Tie every caution to a decisive next step. Vary openings; avoid fillers.\n\n"
    "OUTPUT: one complete sentence addressing Reco’s last line, ending with a concrete check or risk plus a next step."
)

SYSTEM_NEXUS = (
    "You are Agent Nexus, the warm, concise host; welcome listeners, set the purpose, and close cleanly."
)

# ------------------------- FIXED LINES (verbatim) --------------------------
NEXUS_INTRO = (
    "Hello and welcome to Optum MultiAgent Conversation, where intelligence meets collaboration. "
    "I'm Agent Nexus, your host and guide through today's episode. "
    "In this podcast, we bring together specialized agents to explore metrics, data, and decision-making."
)
RECO_INTRO = (
    "Hi everyone, I'm Agent Reco, your go-to for metric recommendations; I focus on impactful measures for performance tracking and optimization."
 )
STAT_INTRO = (
    "Hello! I'm Agent Stat, focused on metric data integrity; I make sure our reads are rigorous and our signals are trustworthy."
)
NEXUS_OUTRO = (
    "That’s a wrap for today’s Optum MultiAgent Conversation; thanks to Reco and Stat for sharp insights, and thanks to you for listening—stay curious and stay data-driven!"
)

# ------------------------- Topic intro --------------------------
async def generate_nexus_topic_intro(context: str) -> str:
    topic_system = (
        "You are Agent Nexus, the host. Introduce the data context in 2 sentences max; "
        "highlight 2–3 notable trends worth discussion by Reco and Stat."
    )
    topic_user = f"Context:\n{context}\nGenerate a brief, engaging intro."
    return await llm(topic_system, topic_user, max_tokens=120, temperature=0.4)

# ------------------------- conversation runner --------------------------
async def run_podcast():
    print("Starting Optum MultiAgent Conversation Podcast Generator (no music)…")
    choice = ask_files()
    context, meta = load_context(choice)
    turns, target_seconds = ask_turns_and_duration()

    conversation_history: List[Dict[str, str]] = []
    audio_segments: List[str] = []
    last_open = {}

    # Intros
    for (text, role) in [(NEXUS_INTRO,"NEXUS"), (RECO_INTRO,"RECO"), (STAT_INTRO,"STAT")]:
        ssml = text_to_ssml(text, role)
        audio_segments.append(synth(ssml))
        conversation_history.append({"speaker": role, "text": text})

    # Topic intro
    topic_intro = await generate_nexus_topic_intro(context)
    topic_intro = ensure_complete_sentence(topic_intro)
    audio_segments.append(synth(text_to_ssml(topic_intro, "NEXUS")))
    conversation_history.append({"speaker":"NEXUS","text":topic_intro})

    # Turns: each turn = Reco + Stat
    for i in range(turns):
        # Reco responds to last STAT or starts
        last_stat = next((m for m in reversed(conversation_history) if m["speaker"]=="STAT"), None)
        prompt_reco = f"Context:\n{context}\n"
        if last_stat:
            prompt_reco += f"Respond to Stat: '{last_stat['text']}' with one actionable recommendation."
        else:
            prompt_reco += "Start with one actionable recommendation grounded in the context."
        reco_line = await llm(SYSTEM_RECO, prompt_reco, 150, 0.45)
        reco_line = vary_opening(reco_line, "RECO", last_open)
        reco_line = _add_conversation_dynamics(reco_line, "RECO", "STAT", context, i+1, conversation_history)
        reco_line = ensure_complete_sentence_line(reco_line)
        audio_segments.append(synth(text_to_ssml(reco_line, "RECO")))
        conversation_history.append({"speaker":"RECO","text":reco_line})

        # Stat replies
        last_reco = conversation_history[-1]
        prompt_stat = f"Context:\n{context}\nReply to Reco's line: '{last_reco['text']}' with one concrete check or risk and next step."
        stat_line = await llm(SYSTEM_STAT, prompt_stat, 150, 0.45)
        stat_line = vary_opening(stat_line, "STAT", last_open)
        stat_line = _add_conversation_dynamics(stat_line, "STAT", "RECO", context, i+1, conversation_history)
        stat_line = ensure_complete_sentence_line(stat_line)
        audio_segments.append(synth(text_to_ssml(stat_line, "STAT")))
        conversation_history.append({"speaker":"STAT","text":stat_line})

    # Outro
    audio_segments.append(synth(text_to_ssml(NEXUS_OUTRO, "NEXUS")))
    conversation_history.append({"speaker":"NEXUS","text":NEXUS_OUTRO})

    # Master
    out = write_master(audio_segments, f"podcast_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.wav")
    total_secs = sum(wav_len(p) for p in audio_segments)
    log_path = f"conversation_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    Path(log_path).write_text(json.dumps({"history":conversation_history,"files_used":meta.get("files",[])}, indent=2), encoding="utf-8")
    print(f"\n✓ Done\nAudio: {out}\nDuration: {total_secs:.1f}s\nLog: {log_path}")

# ------------------------- FastAPI Server --------------------------
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn

app = FastAPI()

class GenerateRequest(BaseModel):
    system_prompt: str
    user_prompt: str
    max_tokens: int = 150
    temperature: float = 0.45

class AudioRequest(BaseModel):
    text: str
    voice: str  # "NEXUS" | "RECO" | "STAT"

@app.post("/generate-response")
async def generate_response(request: GenerateRequest):
    try:
        response = await llm(request.system_prompt, request.user_prompt, request.max_tokens, request.temperature)
        return {"text": response, "success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate-audio")
async def generate_audio_endpoint(request: AudioRequest):
    try:
        ssml = text_to_ssml(request.text, request.voice)
        audio_file = synth(ssml)
        return {"audio_file": audio_file, "success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "podcast-engine", "port": 8001}

# ------------------------- entry ------------------------------------------
if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "serve":
        uvicorn.run(app, host="0.0.0.0", port=8001, reload=True)
    else:
        try:
            asyncio.run(run_podcast())
        except Exception as e:
            print(f"✗ Error: {e}")
            import traceback; traceback.print_exc()
