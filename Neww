import os
import re
import wave
import json
import uuid
import asyncio
import random
import tempfile
from pathlib import Path
from typing import Dict, List, Any, Optional, TypedDict, Literal
from datetime import datetime
from dotenv import load_dotenv
load_dotenv()

# LangGraph (local only)
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
try:
    # optional visualize helper; we fall back if missing
    from langgraph.visualize import draw_async
except Exception:
    draw_async = None

# ============ helpers ============
def ensure_complete_response(text: str) -> str:
    t = text.strip()
    if t and t[-1] not in {'.','!','?'}:
        t += '.'
    return t

def _clean_repetition(text: str) -> str:
    text = re.sub(r'\b(\w+)\s+\1\b', r'\1', text)
    text = re.sub(r'\b(Given that|If we|The safer read),\s+\1', r'\1', text)
    return text

# ============ state ============
class PodcastState(TypedDict):
    messages: List[Dict[str, Any]]
    current_speaker: str
    topic: str
    context: Dict[str, Any]
    interrupted: bool
    audio_segments: List[str]
    conversation_history: List[Dict[str, str]]
    current_turn: float
    max_turns: int
    session_id: str
    node_history: List[Dict[str, Any]]
    current_node: str

# ============ local LLM + TTS (simulated, no keys) ============
async def llm(system: str, prompt: str, max_tokens: int = 150, temperature: float = 0.45) -> str:
    await asyncio.sleep(0.05)
    bank = {
        "asa": [
            "Given the extreme ASA swing, apply a three-month weighted average and confirm queue mapping before adjusting staffing.",
            "That ASA drop is atypical; validate timestamp alignment and route logic, then set a modest improvement glidepath."
        ],
        "duration": [
            "Shorter call duration looks positive; correlate with resolution rate to ensure quality didn’t slip before you trim staffing buffers."
        ],
        "processing": [
            "Processing time volatility suggests seasonality; decompose weekly effects and standardize handoffs across teams."
        ],
    }
    prompt_l = prompt.lower()
    if "asa" in prompt_l: pool = bank["asa"]
    elif "duration" in prompt_l or "call" in prompt_l: pool = bank["duration"]
    elif "processing" in prompt_l: pool = bank["processing"]
    else: pool = bank["asa"] + bank["duration"] + bank["processing"]
    return random.choice(pool)

async def generate_audio(text: str, role: str) -> str:
    await asyncio.sleep(0.02)
    fd, tmp_path = tempfile.mkstemp(suffix='.wav'); os.close(fd)
    with wave.open(tmp_path, 'wb') as wf:
        wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(24000)
        frames = int(24000 * max(0.4, len(text.split()) * 0.12))
        wf.writeframes(b'\x00' * frames * 2)
    return tmp_path

def wav_len(path: str) -> float:
    try:
        with wave.open(path, 'rb') as wf:
            return wf.getnframes() / wf.getframerate()
    except:
        return 1.0

def write_master(segments: List[str], output_path: str) -> str:
    if not segments:
        with wave.open(output_path, 'wb') as wf:
            wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(24000); wf.writeframes(b'')
        return output_path
    with wave.open(segments[0], 'rb') as ref: params = ref.getparams()
    with wave.open(output_path, 'wb') as out:
        out.setparams(params)
        for seg in segments:
            try:
                with wave.open(seg, 'rb') as s: out.writeframes(s.readframes(s.getnframes()))
            except: pass
    return output_path

# ============ fixed lines ============
SYSTEM_RECO = "You are Agent Reco; be concise and actionable."
SYSTEM_STAT = "You are Agent Stat; be rigorous and cautious."
SYSTEM_NEXUS = "You are Agent Nexus; warm intro/outro."

NEXUS_INTRO = ("Hello and welcome to Optum MultiAgent Conversation; I'm Agent Nexus, your host.")
RECO_INTRO  = ("Hi, I'm Agent Reco; I translate metrics into practical actions.")
STAT_INTRO  = ("Hello, I'm Agent Stat; I guard data quality and trend integrity.")
NEXUS_OUTRO = ("Thanks for listening; stay curious and data-driven.")

# ============ load local data.json + metric_data.json (optional) ============
def summarize_local_context() -> str:
    parts = []
    try:
        if Path("data.json").exists():
            d = json.loads(Path("data.json").read_text(encoding="utf-8", errors="ignore"))
            parts.append(f"12-month avg {d.get('12monthAvg','?')}, range {d.get('12monthRange','?')}, MoM {d.get('mom%','?')}.")
        if Path("metric_data.json").exists():
            m = json.loads(Path("metric_data.json").read_text(encoding="utf-8", errors="ignore"))
            for blk in m:
                name = blk.get("metric_name","?")
                last = blk.get("metric_data",[-1])[-1] if blk.get("metric_data") else None
                if last:
                    parts.append(f"{name} latest {last.get('formattedValue', last.get('value'))} on {last.get('measureDate')}.")
    except Exception:
        pass
    return " ".join(parts) or "ASA, call duration, and processing time trends available."

# ============ nodes ============
async def _mark(state: PodcastState, node: str) -> Dict[str, Any]:
    evt = {"node": node, "timestamp": datetime.now().isoformat()}
    print(f"▶ node: {node}")
    return {"node_history": state["node_history"] + [evt], "current_node": node}

async def nexus_intro_node(state: PodcastState) -> Dict[str, Any]:
    audio = await generate_audio(NEXUS_INTRO, "NEXUS")
    delta = await _mark(state, "nexus_intro")
    return {
        **delta,
        "messages": add_messages(state["messages"], [{"role":"system","content":NEXUS_INTRO}]),
        "audio_segments": state["audio_segments"] + [audio],
        "conversation_history": state["conversation_history"] + [{"speaker":"NEXUS","text":NEXUS_INTRO}],
        "current_speaker": "RECO",
    }

async def reco_intro_node(state: PodcastState) -> Dict[str, Any]:
    audio = await generate_audio(RECO_INTRO, "RECO")
    delta = await _mark(state, "reco_intro")
    return {
        **delta,
        "messages": add_messages(state["messages"], [{"role":"system","content":RECO_INTRO}]),
        "audio_segments": state["audio_segments"] + [audio],
        "conversation_history": state["conversation_history"] + [{"speaker":"RECO","text":RECO_INTRO}],
        "current_speaker": "STAT",
    }

async def stat_intro_node(state: PodcastState) -> Dict[str, Any]:
    audio = await generate_audio(STAT_INTRO, "STAT")
    delta = await _mark(state, "stat_intro")
    return {
        **delta,
        "messages": add_messages(state["messages"], [{"role":"system","content":STAT_INTRO}]),
        "audio_segments": state["audio_segments"] + [audio],
        "conversation_history": state["conversation_history"] + [{"speaker":"STAT","text":STAT_INTRO}],
        "current_speaker": "NEXUS",
    }

async def nexus_topic_intro_node(state: PodcastState) -> Dict[str, Any]:
    intro = await llm(SYSTEM_NEXUS, f"Introduce topic: {state['topic']}; context: {state['context'].get('summary','')}", 120, 0.4)
    intro = ensure_complete_response(intro)
    audio = await generate_audio(intro, "NEXUS")
    delta = await _mark(state, "nexus_topic_intro")
    return {
        **delta,
        "messages": add_messages(state["messages"], [{"role":"system","content":intro}]),
        "audio_segments": state["audio_segments"] + [audio],
        "conversation_history": state["conversation_history"] + [{"speaker":"NEXUS","text":intro}],
        "current_speaker": "RECO",
        "current_turn": 0.0,
    }

async def reco_turn_node(state: PodcastState) -> Dict[str, Any]:
    last_stat = next((m for m in reversed(state["conversation_history"]) if m["speaker"]=="STAT"), None)
    prompt = f"Context: {state['context'].get('summary','metrics')}. "
    if last_stat:
        prompt += f"Reply to Stat: '{last_stat['text']}' with one recommendation."
    else:
        prompt += "Start with one recommendation."
    line = ensure_complete_response(await llm(SYSTEM_RECO, prompt, 150, 0.45))
    audio = await generate_audio(line, "RECO")
    delta = await _mark(state, "reco_turn")
    return {
        **delta,
        "messages": add_messages(state["messages"], [{"role":"system","content":line}]),
        "audio_segments": state["audio_segments"] + [audio],
        "conversation_history": state["conversation_history"] + [{"speaker":"RECO","text":line}],
        "current_speaker": "STAT",
        "current_turn": state["current_turn"] + 0.5,
    }

async def stat_turn_node(state: PodcastState) -> Dict[str, Any]:
    last_reco = next((m for m in reversed(state["conversation_history"]) if m["speaker"]=="RECO"), None)
    prompt = f"Context: {state['context'].get('summary','metrics')}. "
    if last_reco:
        prompt += f"Reply to Reco: '{last_reco['text']}' with one check or risk and a next step."
    else:
        prompt += "Provide a cautious integrity check."
    line = ensure_complete_response(await llm(SYSTEM_STAT, prompt, 150, 0.45))
    audio = await generate_audio(line, "STAT")
    delta = await _mark(state, "stat_turn")
    next_speaker = "RECO" if state["current_turn"] + 0.5 < state["max_turns"] else "NEXUS"
    return {
        **delta,
        "messages": add_messages(state["messages"], [{"role":"system","content":line}]),
        "audio_segments": state["audio_segments"] + [audio],
        "conversation_history": state["conversation_history"] + [{"speaker":"STAT","text":line}],
        "current_speaker": next_speaker,
        "current_turn": state["current_turn"] + 0.5,
    }

async def nexus_outro_node(state: PodcastState) -> Dict[str, Any]:
    audio = await generate_audio(NEXUS_OUTRO, "NEXUS")
    delta = await _mark(state, "nexus_outro")
    return {
        **delta,
        "messages": add_messages(state["messages"], [{"role":"system","content":NEXUS_OUTRO}]),
        "audio_segments": state["audio_segments"] + [audio],
        "conversation_history": state["conversation_history"] + [{"speaker":"NEXUS","text":NEXUS_OUTRO}],
        "current_speaker": "END",
    }

def should_continue(state: PodcastState) -> Literal["continue_conversation","end_conversation"]:
    return "end_conversation" if state["current_turn"] >= state["max_turns"] else "continue_conversation"

# ============ graph ============
def create_podcast_graph():
    builder = StateGraph(PodcastState)
    builder.add_node("nexus_intro", nexus_intro_node)
    builder.add_node("reco_intro",  reco_intro_node)
    builder.add_node("stat_intro",  stat_intro_node)
    builder.add_node("nexus_topic_intro", nexus_topic_intro_node)
    builder.add_node("reco_turn",   reco_turn_node)
    builder.add_node("stat_turn",   stat_turn_node)
    builder.add_node("nexus_outro", nexus_outro_node)
    builder.set_entry_point("nexus_intro")
    builder.add_edge("nexus_intro","reco_intro")
    builder.add_edge("reco_intro","stat_intro")
    builder.add_edge("stat_intro","nexus_topic_intro")
    builder.add_edge("nexus_topic_intro","reco_turn")
    builder.add_conditional_edges("reco_turn", should_continue, {
        "continue_conversation":"stat_turn",
        "end_conversation":"nexus_outro"
    })
    builder.add_conditional_edges("stat_turn", should_continue, {
        "continue_conversation":"reco_turn",
        "end_conversation":"nexus_outro"
    })
    builder.add_edge("nexus_outro", END)
    return builder.compile()

async def _save_graph_png(graph, state, prefix: str):
    path = f"{prefix}.png"
    if draw_async is None:
        # fallback: ASCII structure
        try:
            ascii_map = graph.get_graph().draw_ascii()
            Path(f"{prefix}.txt").write_text(ascii_map, encoding="utf-8")
            print(f"ASCII graph saved to {prefix}.txt")
        except Exception as e:
            print(f"Graph ASCII fallback failed: {e}")
        return None
    try:
        await draw_async(graph, config=state, output_file=path, dpi=300, format="png")
        print(f"Graph image saved: {path}")
        return path
    except Exception as e:
        print(f"Visualization error: {e}")
        return None

# ============ main orchestration ============
async def generate_podcast(topic: str, max_turns: int = 4, session_id: Optional[str] = None) -> Dict[str, Any]:
    session_id = session_id or f"pod_{uuid.uuid4().hex[:8]}"
    context_summary = summarize_local_context()
    initial: PodcastState = {
        "messages": [],
        "current_speaker": "NEXUS",
        "topic": topic,
        "context": {"summary": context_summary, "files":[f for f in ["data.json","metric_data.json"] if Path(f).exists()]},
        "interrupted": False,
        "audio_segments": [],
        "conversation_history": [],
        "current_turn": 0.0,
        "max_turns": max_turns,
        "session_id": session_id,
        "node_history": [],
        "current_node": "start"
    }
    graph = create_podcast_graph()
    print("Saving structure visualization…")
    await _save_graph_png(graph, initial, f"structure_{session_id}")
    print("Executing graph…")
    final_state = await graph.ainvoke(initial)
    print("Saving execution visualization…")
    await _save_graph_png(graph, final_state, f"execution_{session_id}")
    out_path = f"podcast_{session_id}.wav"
    write_master(final_state["audio_segments"], out_path)
    log_path = f"conversation_{session_id}.json"
    Path(log_path).write_text(json.dumps({
        "conversation_history": final_state["conversation_history"],
        "node_history": final_state["node_history"],
        "topic": topic,
        "turns": max_turns,
        "generated_at": datetime.now().isoformat()
    }, indent=2), encoding="utf-8")
    duration = sum(wav_len(p) for p in final_state["audio_segments"])
    return {
        "session_id": session_id,
        "audio_file": out_path,
        "conversation_log": log_path,
        "graph_visualization": f"execution_{session_id}.png",
        "duration": duration,
        "turns": max_turns,
        "success": True
    }

# ============ FastAPI ============
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn

app = FastAPI()

class PodcastRequest(BaseModel):
    topic: str
    max_turns: int = 4
    session_id: Optional[str] = None

@app.post("/generate-podcast")
async def api_generate_podcast(request: PodcastRequest):
    try:
        return await generate_podcast(request.topic, request.max_turns, request.session_id)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/graph-visualization/{session_id}")
async def get_graph_visualization(session_id: str):
    s = f"structure_{session_id}.png"
    e = f"execution_{session_id}.png"
    data = {}
    if Path(s).exists(): data["structure_visualization"] = s
    if Path(e).exists(): data["execution_visualization"] = e
    if data: return data
    raise HTTPException(status_code=404, detail="Visualizations not found")

@app.get("/health")
async def health_check():
    return {"status":"healthy","service":"langgraph-podcast","port":8002}

if __name__ == "__main__":
    if len(os.sys.argv) > 1 and os.sys.argv[1] == "serve":
        uvicorn.run(app, host="0.0.0.0", port=8002, reload=True)
    else:
        async def _cli():
            topic = input("Enter topic (e.g., 'ASA metrics analysis'): ").strip() or "metrics analysis"
            try:
                turns = int(input("Turns (2–8): ").strip() or "4")
                turns = max(2, min(8, turns))
            except:
                turns = 4
            res = await generate_podcast(topic, turns)
            print("\n✓ complete")
            for k,v in res.items(): print(f"{k}: {v}")
        asyncio.run(_cli())
