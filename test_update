# podcast_offline_version1.py — 2-minute audio-only A/B debate (smooth), ONE sentence per turn
# - Prompts both agents to use BOTH files: data.json + metric_data.json (or lets you pick)
# - Smooth audio: no beeps/music, steady prosody, small zero-silence between turns
# - No console transcript; saves: podcast_offline_version1.wav, podcast_script.txt, podcast_shownotes.md, podcast_transcript.jsonl
# pip install -U azure-cognitiveservices-speech azure-identity openai python-dotenv

import os, sys, re, wave, json, tempfile, asyncio, datetime, shutil, glob, struct, math
from pathlib import Path
from dotenv import load_dotenv; load_dotenv()

# ========== Azure OpenAI ==========
from openai import AzureOpenAI
AZURE_OPENAI_KEY        = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT   = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION      = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")
if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role":"system","content":system},{"role":"user","content":user}],
        max_tokens=max_tokens, temperature=temperature)
    return (r.choices[0].message.content or "").strip()

async def llm(system: str, user: str, max_tokens: int=110, temperature: float=0.5) -> str:
    return await asyncio.to_thread(llm_sync, system, user, max_tokens, temperature)

# ========== Azure Speech (AAD) ==========
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID     = os.getenv("TENANT_ID")
CLIENT_ID     = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION", "eastus")
RESOURCE_ID   = os.getenv("RESOURCE_ID")  # optional
COG_SCOPE     = "https://cognitiveservices.azure.com/.default"
if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)
def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

VOICE_A = os.getenv("VOICE_A", "en-US-GuyNeural")   # senior analyst
VOICE_B = os.getenv("VOICE_B", "en-US-AriaNeural")  # senior strategist

def ssml_wrapper(inner: str, voice: str, rate: str, pitch: str) -> str:
    # keep it simple for reliability & smoothness (no expressive style tags)
    return f"""<speak version="1.0" xml:lang="en-US"
             xmlns="http://www.w3.org/2001/10/synthesis">
  <voice name="{voice}">
    <prosody rate="{rate}" pitch="{pitch}">
      {inner}
    </prosody>
  </voice>
</speak>"""

def to_ssml(text: str, voice: str, rate: str = "-1%", pitch: str = "0%") -> str:
    # ONE sentence already, but keep tiny trailing pause to prevent cutoffs
    clean = text.strip()
    inner = f"{clean}<break time='200ms'/>"
    return ssml_wrapper(inner, voice, rate, pitch)

def tts_ssml_to_wav(text: str, voice: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)
    fd, tmp_path = tempfile.mkstemp(prefix="agent_tts_", suffix=".wav"); os.close(fd)
    ssml = to_ssml(text, voice)
    audio_cfg = speechsdk.audio.AudioOutputConfig(filename=tmp_path)
    synth = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg)
    res = synth.speak_ssml_async(ssml).get()
    if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp_path
    # plain text fallback
    res = synth.speak_text_async(text).get()
    if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp_path
    try: os.remove(tmp_path)
    except Exception: pass
    raise RuntimeError("TTS canceled")

def append_wav_into_master(src_path: str, master_wf: wave.Wave_write):
    with wave.open(src_path, "rb") as r:
        frames = r.readframes(r.getnframes())
        master_wf.writeframes(frames)

def write_silence(master_wf: wave.Wave_write, ms: int = 160, rate: int = 24000):
    n = int(rate * (ms/1000.0))
    master_wf.writeframes(b"\x00\x00"*n)

def strip_markup(t: str) -> str:
    t = re.sub(r'[`*_#>]+', ' ', t)
    t = re.sub(r'\s{2,}', ' ', t).strip()
    return t

# ========== Prompts: ONE sentence per turn ==========
SYSTEM_A = """
You are Agent A, a senior data analyst debating live with Agent B (a strategist).
SPEAK EXACTLY ONE SENTENCE (18–28 words). No lists, headings, hashtags, or filenames.
You have two datasets: weekly aggregates (2022–2025: 12-mo averages/ranges, full-series min/max, YTD totals/averages, WoW/MoM deltas) and monthly KPIs (ASA seconds, Average Call Duration minutes, Claim Processing Time days, plus any other metrics present).
Your single sentence must synthesize across ALL metrics, cite concrete ranges/deltas, link weekly aggregates to monthly KPIs with an operational implication, and end with a pointed question to Agent B.
"""

SYSTEM_B = """
You are Agent B, a senior strategist debating live with Agent A.
SPEAK EXACTLY ONE SENTENCE (18–28 words). No lists, headings, hashtags, or filenames.
Diagnose plausible drivers (seasonality, staffing, routing/SLA, backlog, demand mix) grounded in the datasets, tie macro weekly aggregates to monthly KPIs, and end with a concrete next step or trade-off for A.
"""

# ========== File selection ==========
def ask_file_choice() -> str:
    base = Path(".").resolve()
    names = [p.name for p in base.iterdir() if p.suffix.lower()==".json"]
    print("JSON files in folder:", names)
    print("Type: data.json, metric_data.json, both (recommended), or an exact .json filename, then Enter:")
    choice = sys.stdin.readline().strip().lower()
    return choice or "both"

def load_context(choice: str) -> tuple[str, dict]:
    ctx = ""
    meta = {"files":[]}
    def add(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    if choice == "both":
        # exactly the two you said
        ctx += add("data.json")
        ctx += add("metric_data.json")
    else:
        p = Path(choice)
        if p.exists() and p.suffix.lower()==".json":
            ctx += add(p.name)
        else:
            if "data" in choice: ctx += add("data.json")
            if "metric" in choice: ctx += add("metric_data.json")
    if not ctx:
        # fallback to both if present
        if Path("data.json").exists():           ctx += add("data.json")
        if Path("metric_data.json").exists():    ctx += add("metric_data.json")
    if not ctx:
        raise RuntimeError("Expected data.json and/or metric_data.json in the current folder.")
    return ctx, meta

# ========== Debate settings ==========
TARGET_SECONDS = 120.0
TURNS = 6  # A/B × 6 = 12 sentences (≈2 min with silences)

def make_a_audio(text: str) -> str:
    return tts_ssml_to_wav(strip_markup(text), VOICE_A)

def make_b_audio(text: str) -> str:
    return tts_ssml_to_wav(strip_markup(text), VOICE_B)

# ========== Output paths + safe finalize ==========
OUT_WAV_BASE   = "podcast_offline_version1.wav"
SCRIPT_TXT     = "podcast_script.txt"
SHOW_NOTES     = "podcast_shownotes.md"
TRANS_JSON     = "podcast_transcript.jsonl"
TITLE          = "Ops Signals — Two-Minute Data Debate"

def unique_tmp_out() -> str:
    fd, p = tempfile.mkstemp(prefix="podcast_", suffix=".wav")
    os.close(fd)
    return p

def finalize_out(tmp_path: str, final_path: str) -> str:
    try:
        if Path(final_path).exists():
            try: os.remove(final_path)
            except Exception: pass
        os.replace(tmp_path, final_path)
        return final_path
    except Exception:
        ts = f"{Path(final_path).stem}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
        ts_path = str(Path(final_path).with_name(ts))
        shutil.move(tmp_path, ts_path)
        print(f"Saved as {ts_path} (target in use).")
        return ts_path

# ========== Main ==========
async def run_podcast():
    choice = ask_file_choice()
    context, meta = load_context(choice)

    transcript = []
    with open(TRANS_JSON, "w", encoding="utf-8") as _: pass  # truncate

    tmp_out = unique_tmp_out()
    try:
        with wave.open(tmp_out, "wb") as master_wf:
            master_wf.setnchannels(1); master_wf.setsampwidth(2); master_wf.setframerate(24000)
            elapsed = 0.0

            def log(role: str, text: str, tsec: float):
                entry = {"ts": datetime.datetime.now().isoformat(), "t": round(tsec,2), "role": role, "text": text}
                transcript.append(f"{role}: {text}")
                with open(TRANS_JSON, "a", encoding="utf-8") as f:
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")

            # Brief narration (one sentence)
            intro = "Welcome to Ops Signals, a fast two-minute debate where a senior analyst and strategist turn your raw metrics into decisions."
            wi = make_a_audio(intro); append_wav_into_master(wi, master_wf); os.remove(wi)
            write_silence(master_wf, 220);  # gentle spacing
            log("Narration", intro, elapsed)

            seed = f"Use these datasets as the sole factual source. Keep conversation style; one sentence per turn.\n{context[:12000]}"
            last = seed

            # Strict A/B, one sentence each, with small inter-turn silences to keep audio smooth
            for _ in range(TURNS):
                # A
                a_out = await llm(SYSTEM_A, last, max_tokens=110, temperature=0.47)
                wa = make_a_audio(a_out); append_wav_into_master(wa, master_wf); os.remove(wa)
                write_silence(master_wf, 160)
                log("Agent A", a_out, elapsed)

                # B
                b_in = f"Agent A just said: {a_out}\nReference (do not read filenames):\n{context[:9000]}"
                b_out = await llm(SYSTEM_B, b_in, max_tokens=110, temperature=0.47)
                wb = make_b_audio(b_out); append_wav_into_master(wb, master_wf); os.remove(wb)
                write_silence(master_wf, 160)
                log("Agent B", b_out, elapsed)

                last = b_out

            # Close (one sentence)
            close = "That’s the brief—clear signals, concrete levers, and a path to act now."
            wc = make_b_audio(close); append_wav_into_master(wc, master_wf); os.remove(wc)
            write_silence(master_wf, 200)
            log("Narration", close, elapsed)

    finally:
        pass

    final_out = finalize_out(tmp_out, OUT_WAV_BASE)

    # Save script + notes (no console prints of dialogue)
    with open(SCRIPT_TXT, "w", encoding="utf-8") as f:
        f.write("\n".join(transcript))

    total_sec = 0
    try:
        with wave.open(final_out, "rb") as r:
            total_sec = r.getnframes() / r.getframerate()
    except Exception:
        pass

    with open(SHOW_NOTES, "w", encoding="utf-8") as f:
        f.write(f"# {TITLE}\n")
        f.write(f"- **Recorded**: {datetime.datetime.now().isoformat()}\n")
        f.write(f"- **Duration**: ~{int(total_sec)}s\n")
        f.write(f"- **Files used**: {', '.join(meta['files'])}\n")
        f.write("\n## Structure\n- Intro (1 sentence)\n- A/B debate (12 sentences total)\n- Close (1 sentence)\n")
        f.write("\n## Notes\n- Senior tone; one sentence per turn for crisp cadence\n- ALL metrics considered across datasets\n- Concrete ranges, YTD & month deltas, operational implications\n")

    print(f"Saved: {final_out}, {SCRIPT_TXT}, {SHOW_NOTES}, {TRANS_JSON}")

if __name__ == "__main__":
    try:
        asyncio.run(run_podcast())
    except Exception as e:
        print(f"Error: {e}")
