# podcast_professional.py — Enhanced professional podcast with Azure OpenAI + Azure Speech
# pip install -U azure-cognitiveservices-speech azure-identity openai python-dotenv

import os, sys, re, math, wave, json, tempfile, asyncio, datetime, shutil, atexit
from pathlib import Path
from dotenv import load_dotenv; load_dotenv()

# ========== Global variables and setup ==========
temp_files = []  # Track temporary files for cleanup

@atexit.register
def cleanup_temp_files():
    """Clean up all temporary files on exit"""
    for file in temp_files:
        try:
            if os.path.exists(file):
                os.remove(file)
        except Exception:
            pass

# ========== Azure OpenAI ==========
from openai import AzureOpenAI, BadRequestError
AZURE_OPENAI_KEY        = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT   = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION      = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")
if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role":"system","content":system},{"role":"user","content":user}],
        max_tokens=max_tokens, temperature=temperature)
    return (r.choices[0].message.content or "").strip()

# ===== Softener + Safe Retry =====
def soften_user_seed(text: str) -> str:
    t = text
    t = re.sub(r'\b[Ss]ole factual source\b', 'primary context', t)
    t = re.sub(r'\b[Dd]o not\b', 'please avoid', t)
    t = re.sub(r"\b[Dd]on't\b", 'please avoid', t)
    t = re.sub(r'\b[Ii]gnore\b', 'do not rely on', t)
    t = t.replace("debate", "discussion").replace("Debate", "Discussion")
    return t

def one_sentence_only(text: str) -> str:
    t = text.strip()
    t = re.sub(r'[`*_#>]+', ' ', t)
    t = re.sub(r'\s{2,}', ' ', t).strip()
    parts = re.split(r'(?<=[.!?])\s+', t)
    for p in parts:
        p = p.strip()
        if p:
            if len(p.split()) > 30:
                words = p.split()
                p = " ".join(words[:28]) + "…"
            return p
    return t

def validate_response(text: str) -> bool:
    """Check if response meets quality standards"""
    if not text or len(text.strip()) < 10:
        return False
    if text.count(".") > 2:  # Too many sentences
        return False
    if text.isupper():  # ALL CAPS
        return False
    if re.search(r'http[s]?://', text):  # URLs
        return False
    return True

def llm_sync_safe(system: str, user: str, max_tokens: int, temperature: float) -> str:
    try:
        out = llm_sync(system, user, max_tokens, temperature)
        if not validate_response(out):
            # Try again with different parameters if validation fails
            out = llm_sync(system, user, max_tokens=100, temperature=min(0.8, temperature + 0.1))
        return one_sentence_only(out)
    except BadRequestError as e:
        msg = str(e)
        if "content management policy" in msg or "content filter" in msg or getattr(e, "status_code", None) == 400:
            soft_system = system.replace("debate", "discussion").replace("Debate", "Discussion")
            soft_user   = soften_user_seed(user)
            try:
                out = llm_sync(
                    soft_system + " Always comply with safety policies and keep a professional, neutral tone.",
                    soft_user,
                    max_tokens=max(60, max_tokens-20),
                    temperature=max(0.1, temperature-0.2)
                )
                return one_sentence_only(out)
            except Exception:
                minimal_system = "You are a professional analyst. Produce one safe, neutral sentence grounded in the provided context."
                minimal_user   = "Summarize cross-metric trends and propose one action in a single safe sentence."
                out = llm_sync(minimal_system, minimal_user, max_tokens=80, temperature=0.2)
                return one_sentence_only(out)
        raise

async def llm(system: str, user: str, max_tokens: int=120, temperature: float=0.45) -> str:
    return await asyncio.to_thread(llm_sync_safe, system, user, max_tokens, temperature)

# ========== Azure Speech (AAD) ==========
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID     = os.getenv("TENANT_ID")
CLIENT_ID     = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION", "eastus")
RESOURCE_ID   = os.getenv("RESOURCE_ID")  # optional
COG_SCOPE     = "https://cognitiveservices.azure.com/.default"
if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)
def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

# Updated voice assignments as requested
VOICE_NEXUS = os.getenv("AZURE_VOICE_HOST", "en-US-JennyNeural")  # Lady voice for Agent Nexus
VOICE_RECO = os.getenv("AZURE_VOICE_BA", "en-US-JennyNeural")     # Agent Reco
VOICE_STATIX = os.getenv("AZURE_VOICE_DA", "en-US-BrianNeural")   # Agent Statix

# Voice settings for more natural delivery
VOICE_SETTINGS = {
    "NEXUS": {"style": "friendly", "rate": "-3%", "pitch": "+2%"},
    "RECO": {"style": "newscast-casual", "rate": "-4%", "pitch": "0%"},
    "STATIX": {"style": "serious", "rate": "-5%", "pitch": "-1%"}
}

def ssml_wrapper(inner: str, voice: str, style: str | None, rate: str, pitch: str) -> str:
    if style:
        return f"""<speak version="1.0" xml:lang="en-US"
                 xmlns="http://www.w3.org/2001/10/synthesis"
                 xmlns:mstts="http://www.w3.org/2001/mstts">
  <voice name="{voice}">
    <mstts:express-as style="{style}">
      <prosody rate="{rate}" pitch="{pitch}">
        {inner}
      </prosody>
    </mstts:express-as>
  </voice>
</speak>"""
    else:
        return f"""<speak version="1.0" xml:lang="en-US"
                 xmlns="http://www.w3.org/2001/10/synthesis">
  <voice name="{voice}">
    <prosody rate="{rate}" pitch="{pitch}">
      {inner}
    </prosody>
  </voice>
</speak>"""

def to_ssml(text: str, voice: str, style: str | None, rate: str = "-6%", pitch: str = "0%") -> str:
    t = text.strip()
    t = t.replace(",", ",<break time='220ms'/>")
    inner = f"{t}<break time='320ms'/>"
    return ssml_wrapper(inner, voice, style, rate, pitch)

def tts_ssml_to_wav_with_fallback(text: str, voice: str, style: str | None, rate: str, pitch: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(
        speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm
    )
    fd, tmp_path = tempfile.mkstemp(prefix="agent_tts_", suffix=".wav"); os.close(fd)
    temp_files.append(tmp_path)
    try:
        try_styles = [style, None] if style else [None]
        for sty in try_styles:
            ssml = to_ssml(text, voice, sty, rate, pitch)
            audio_cfg = speechsdk.audio.AudioOutputConfig(filename=tmp_path)
            synth = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg)
            res = synth.speak_ssml_async(ssml).get()
            if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                return tmp_path
        # Plain text fallback
        audio_cfg = speechsdk.audio.AudioOutputConfig(filename=tmp_path)
        synth = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg)
        res = synth.speak_text_async(text).get()
        if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return tmp_path
        raise RuntimeError("TTS canceled even after SSML/style fallbacks")
    except Exception as e:
        try: 
            os.remove(tmp_path)
            if tmp_path in temp_files:
                temp_files.remove(tmp_path)
        except Exception: 
            pass
        # Add more specific error information
        if "401" in str(e):
            raise RuntimeError("Authentication failed - check AAD credentials")
        elif "404" in str(e):
            raise RuntimeError("Voice not found - check voice name")
        else:
            raise RuntimeError(f"TTS failed: {str(e)}")

def get_wav_duration_seconds(path: str) -> float:
    with wave.open(path, "rb") as r:
        frames = r.getnframes(); rate = r.getframerate()
        return (frames / float(rate)) if rate else 0.0

# ========== Audio utilities ==========
def add_silence(duration_ms: int = 300) -> str:
    """Generate a silent WAV segment"""
    fd, p = tempfile.mkstemp(prefix="silence_", suffix=".wav")
    os.close(fd)
    temp_files.append(p)
    with wave.open(p, "wb") as w:
        w.setnchannels(1)
        w.setsampwidth(2)
        w.setframerate(24000)
        # Calculate number of frames for silence
        frames = int(24000 * duration_ms / 1000)
        w.writeframes(b'\x00' * frames * 2)  # 16-bit samples
    return p

# ========== Atomic master WAV writer ==========
def render_master_wav(segment_paths: list[str], out_path: str, rate: int = 24000):
    """Write all segments to a temp WAV and atomically replace the target."""
    # Write to temp first
    fd, tmp = tempfile.mkstemp(prefix="podcast_", suffix=".wav")
    os.close(fd)
    temp_files.append(tmp)
    try:
        with wave.open(tmp, "wb") as w:
            w.setnchannels(1); w.setsampwidth(2); w.setframerate(rate)
            for seg in segment_paths:
                with wave.open(seg, "rb") as r:
                    # sanity check (we generate everything at 24k/16-bit/mono)
                    if r.getframerate() != rate or r.getnchannels() != 1 or r.getsampwidth() != 2:
                        # If a mismatch ever occurs, fail fast to avoid corrupt audio
                        raise RuntimeError(f"Segment format mismatch: {seg}")
                    w.writeframes(r.readframes(r.getnframes()))
        # Atomic replace (Windows-safe if target not open)
        try:
            os.replace(tmp, out_path)
            if tmp in temp_files:
                temp_files.remove(tmp)
        except PermissionError:
            # write to a new file instead of failing
            base, ext = os.path.splitext(out_path)
            alt = f"{base}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}{ext}"
            os.replace(tmp, alt)
            print(f"⚠️ Output was locked; wrote to {alt}")
            return alt
        return out_path
    except Exception:
        try: 
            os.remove(tmp)
            if tmp in temp_files:
                temp_files.remove(tmp)
        except Exception: 
            pass
        raise

# ========== Prompts (safe, one sentence per turn) ==========
SYSTEM_RECO = (
    "You are Agent Reco, specializing in metric recommendations. "
    "Speak in one clear sentence (about 15-25 words). Identify the most impactful metrics "
    "for performance tracking, optimization, and strategic alignment. Keep it professional but conversational."
)

SYSTEM_STATIX = (
    "You are Agent Statix, focused on metric data. "
    "Speak in one clear sentence (about 15-25 words). Dive deep into data sources, trends, "
    "and statistical integrity to ensure our metrics are not just smart—but solid. "
    "Keep it professional but conversational."
)

# ========== File selection & context ==========
def ask_file_choice() -> str:
    base = Path(".").resolve()
    jsons = [p.name for p in base.iterdir() if p.suffix.lower() == ".json"]
    print("JSON files in folder:", jsons)
    print("Type one of: data.json, metric.json, metric_data.json, both (recommended), or an exact filename, then Enter:")
    choice = sys.stdin.readline().strip().lower()
    return choice or "both"

def load_context(choice: str) -> tuple[str, dict]:
    ctx = ""
    meta = {"files":[]}
    def add_file(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    if choice == "both":
        ctx += add_file("data.json")
        if Path("metric_data.json").exists():
            ctx += add_file("metric_data.json")
        else:
            ctx += add_file("metric.json")
    else:
        p = Path(choice)
        if p.exists() and p.suffix.lower()==".json":
            ctx += add_file(p.name)
        else:
            if "data" in choice: ctx += add_file("data.json")
            if "metric_data" in choice or "metric" in choice:
                if Path("metric_data.json").exists():
                    ctx += add_file("metric_data.json")
                else:
                    ctx += add_file("metric.json")
    if not ctx:
        if Path("data.json").exists(): ctx += add_file("data.json")
        if Path("metric_data.json").exists(): ctx += add_file("metric_data.json")
        elif Path("metric.json").exists(): ctx += add_file("metric.json")
    if not ctx:
        raise RuntimeError("No data found (need data.json and/or metric_data.json/metric.json).")
    return ctx, meta

def ask_turns_and_duration() -> tuple[int, float]:
    print("Enter desired number of Reco/Statix turns (each turn = Reco then Statix). Press Enter for default 6 turns:")
    try:
        t = sys.stdin.readline().strip()
        turns = int(t) if t else 6
    except Exception:
        turns = 6
    turns = max(4, min(10, turns))
    print("Enter desired duration in minutes (2–5). Press Enter for default 3:")
    try:
        m = sys.stdin.readline().strip()
        minutes = float(m) if m else 3.0
    except Exception:
        minutes = 3.0
    minutes = max(2.0, min(5.0, minutes))
    return turns, minutes*60.0

# ========== Voices & helpers ==========
def make_nexus_audio(text: str) -> str:
    settings = VOICE_SETTINGS["NEXUS"]
    return tts_ssml_to_wav_with_fallback(text, VOICE_NEXUS, settings["style"], settings["rate"], settings["pitch"])

def make_reco_audio(text: str) -> str:
    settings = VOICE_SETTINGS["RECO"]
    return tts_ssml_to_wav_with_fallback(text, VOICE_RECO, settings["style"], settings["rate"], settings["pitch"])

def make_statix_audio(text: str) -> str:
    settings = VOICE_SETTINGS["STATIX"]
    return tts_ssml_to_wav_with_fallback(text, VOICE_STATIX, settings["style"], settings["rate"], settings["pitch"])

def setup_output_directory():
    """Create a dedicated output directory with timestamp"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(f"podcast_output_{timestamp}")
    output_dir.mkdir(exist_ok=True)
    return output_dir

# ========== Enhanced Main Function ==========
async def run_enhanced_podcast():
    # Setup output directory
    output_dir = setup_output_directory()
    OUT_WAV = output_dir / "podcast_enhanced.wav"
    SCRIPT_TXT = output_dir / "script_enhanced.txt"
    SHOW_NOTES = output_dir / "shownotes_enhanced.md"
    TRANS_JSON = output_dir / "transcript_enhanced.jsonl"
    TITLE = "Optum MultiAgent Conversation"
    
    print("Loading context...")
    choice = ask_file_choice()
    context, meta = load_context(choice)
    turns, target_seconds = ask_turns_and_duration()

    with open(TRANS_JSON, "w", encoding="utf-8") as _: 
        pass  # Clear previous content
    
    transcript = []
    t0 = datetime.datetime.now().isoformat()

    # Build all audio segments
    segments = []
    elapsed = 0.0

    def log(role: str, text: str, tsec: float):
        entry = {"ts": datetime.datetime.now().isoformat(), "t": round(tsec, 2), "role": role, "text": text}
        transcript.append(f"{role}: {text}")
        with open(TRANS_JSON, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    # Agent Nexus introduction
    print("Creating Agent Nexus introduction...")
    nexus_intro = "Hello and welcome to Optum MultiAgent Conversation, where intelligence meets collaboration. I'm Agent Nexus, your host and guide through today's episode. In this podcast, we bring together specialized agents to explore the world of metrics, data, and decision-making. Let's meet today's experts."
    nexus_audio = make_nexus_audio(nexus_intro)
    segments.append(nexus_audio)
    elapsed += get_wav_duration_seconds(nexus_audio)
    log("Agent Nexus", nexus_intro, elapsed)
    
    # Add pause after introduction
    segments.append(add_silence(500))
    elapsed += 0.5

    # Agent Reco introduction
    print("Creating Agent Reco introduction...")
    reco_intro = "Hi everyone, I'm Agent Reco, your go-to for metric recommendations. I specialize in identifying the most impactful metrics for performance tracking, optimization, and strategic alignment."
    reco_audio = make_reco_audio(reco_intro)
    segments.append(reco_audio)
    elapsed += get_wav_duration_seconds(reco_audio)
    log("Agent Reco", reco_intro, elapsed)
    
    # Add pause between agents
    segments.append(add_silence(400))
    elapsed += 0.4

    # Agent Statix introduction
    print("Creating Agent Statix introduction...")
    statix_intro = "Hello! I'm Agent Statix, focused on metric data. I dive deep into data sources, trends, and statistical integrity to ensure our metrics are not just smart—but solid."
    statix_audio = make_statix_audio(statix_intro)
    segments.append(statix_audio)
    elapsed += get_wav_duration_seconds(statix_audio)
    log("Agent Statix", statix_intro, elapsed)
    
    # Add pause before conversation starts
    segments.append(add_silence(600))
    elapsed += 0.6

    # Main conversation
    seed = soften_user_seed("Use these datasets as primary context; keep a natural one-sentence discussion.\n" + context[:12000])
    last = seed
    
    print("Generating podcast segments...")
    for i in range(turns):
        print(f"Processing turn {i+1}/{turns}...")
        if elapsed >= target_seconds: 
            break
            
        # Agent Reco turn
        reco_out = await llm(SYSTEM_RECO, last, max_tokens=120, temperature=0.45)
        w_reco = make_reco_audio(reco_out)
        segments.append(w_reco)
        d_reco = get_wav_duration_seconds(w_reco)
        elapsed += d_reco
        log("Agent Reco", reco_out, elapsed)
        
        # Add natural pause between speakers
        segments.append(add_silence(300))
        elapsed += 0.3
        
        if elapsed >= target_seconds: 
            break
            
        # Agent Statix turn
        statix_in = soften_user_seed(f"Agent Reco just said: {reco_out}\nReference context (no need to name files):\n{context[:9000]}")
        statix_out = await llm(SYSTEM_STATIX, statix_in, max_tokens=120, temperature=0.45)
        w_statix = make_statix_audio(statix_out)
        segments.append(w_statix)
        d_statix = get_wav_duration_seconds(w_statix)
        elapsed += d_statix
        log("Agent Statix", statix_out, elapsed)
        
        # Add pause between conversation turns
        segments.append(add_silence(400))
        elapsed += 0.4
        last = statix_out

    # Agent Nexus conclusion
    print("Creating Agent Nexus conclusion...")
    nexus_outro = "Thank you to Agents Reco and Statix for their insights, and thank you to our listeners for joining us today on Optum MultiAgent Conversation."
    nexus_outro_audio = make_nexus_audio(nexus_outro)
    segments.append(nexus_outro_audio)
    elapsed += get_wav_duration_seconds(nexus_outro_audio)
    log("Agent Nexus", nexus_outro, elapsed)

    print("Rendering final audio...")
    out_written = render_master_wav(segments, OUT_WAV)
    
    # Cleanup
    for p in segments:
        try: 
            if os.path.exists(p) and p not in temp_files:
                os.remove(p)
        except Exception: 
            pass

    # Enhanced show notes
    total_sec = 0.0
    try:
        with wave.open(out_written, "rb") as r:
            total_sec = r.getnframes() / r.getframerate()
    except Exception:
        pass
        
    with open(SHOW_NOTES, "w", encoding="utf-8") as f:
        f.write(f"# {TITLE}\n\n")
        f.write(f"## Episode Details\n")
        f.write(f"- **Recorded**: {t0}\n")
        f.write(f"- **Duration**: {int(total_sec // 60)}m {int(total_sec % 60)}s\n")
        f.write(f"- **Data Sources**: {', '.join(meta['files'])}\n\n")
        
        f.write(f"## Participants\n")
        f.write("- 🎧 **Agent Nexus**: Host and guide\n")
        f.write("- 🔵 **Agent Reco**: Metric recommendations specialist\n")
        f.write("- 🔴 **Agent Statix**: Metric data and statistical integrity expert\n\n")
        
        f.write(f"## Episode Summary\n")
        f.write("This episode features a discussion between Agent Reco and Agent Statix, ")
        f.write("breaking down the latest metrics and trends from our datasets.\n\n")
        
        f.write(f"## Key Topics Discussed\n")
        for i, line in enumerate(transcript[3:9]):  # Show first few talking points after introductions
            if i % 2 == 0:  # Just show a few highlights
                f.write(f"- {line.split(':', 1)[1].strip()}\n")
        
        f.write(f"\n## Next Steps\n")
        f.write("To dive deeper into these metrics, explore the full datasets referenced in this episode.")

    print(f"Enhanced podcast saved: {out_written}")
    print(f"Additional files: {SCRIPT_TXT}, {SHOW_NOTES}, {TRANS_JSON}")

# ---------- Entry Point ----------
if __name__ == "__main__":
    try:
        print("Starting Optum MultiAgent Conversation Podcast Generator...")
        asyncio.run(run_enhanced_podcast())
            
    except KeyboardInterrupt:
        print("\nStopped.")
    except Exception as e:
        print(f"X Error: {e}")
        import traceback
        traceback.print_exc()
