def llm_tool_sync(panel_prompt: str, msg: str) -> str:
    """
    Tool-aware completion that ALWAYS exposes tools on every turn and
    lets the model call tools repeatedly until it stops (bounded by hops).
    """
    MAX_TOOL_HOPS = 6  # prevent infinite loops
    messages = [
        {"role": "system", "content": panel_prompt},
        {"role": "user",   "content": msg},
    ]

    for _ in range(MAX_TOOL_HOPS):
        # Always expose tools and allow tool calls
        r = oai.chat.completions.create(
            model=AZURE_OPENAI_DEPLOYMENT,
            messages=messages,
            tools=TOOLS_SCHEMA,
            tool_choice="auto",     # allow ANY tool if the model wants one
            temperature=0.7,
            max_tokens=350,
        )
        choice = r.choices[0]
        assistant_msg = choice.message
        tool_calls = getattr(assistant_msg, "tool_calls", None)

        # Append assistant step exactly as returned (with tool_calls if any)
        messages.append({
            "role": "assistant",
            "content": assistant_msg.content or "",
            **({"tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments or "{}",
                        },
                    } for tc in (tool_calls or [])
                ]} if tool_calls else {})
        })

        # If no tools requested, we’re done — return the final assistant text
        if not tool_calls:
            return (assistant_msg.content or "").strip()

        # Execute each tool call and append the tool results
        for tc in tool_calls:
            fn = tc.function
            name = fn.name
            try:
                args = json.loads(fn.arguments or "{}")
            except Exception:
                args = {}
            result = _call_tool(name, args)
            messages.append({
                "role": "tool",
                "tool_call_id": tc.id,
                "name": name,
                "content": json.dumps(result, ensure_ascii=False),
            })

        # loop continues: the next iteration gives the model the tool outputs
        # and again allows further tool calls if it wants

    # If we hit MAX_TOOL_HOPS without a final answer, return last assistant text
    # or a safe notice.
    for m in reversed(messages):
        if m["role"] == "assistant" and (m.get("content") or "").strip():
            return m["content"].strip()
    return "I ran multiple tool steps but didn’t produce a final answer."
