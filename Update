# podcast_professional.py â€” Enhanced professional podcast with Azure OpenAI + Azure Speech
# pip install -U azure-cognitiveservices-speech azure-identity openai python-dotenv

import os, sys, re, math, wave, json, tempfile, asyncio, datetime, shutil, atexit
from pathlib import Path
from dotenv import load_dotenv; load_dotenv()

# ========== Global variables and setup ==========
temp_files = []  # Track temporary files for cleanup

@atexit.register
def cleanup_temp_files():
    """Clean up all temporary files on exit"""
    for file in temp_files:
        try:
            if os.path.exists(file):
                os.remove(file)
        except Exception:
            pass

# ========== Azure OpenAI ==========
from openai import AzureOpenAI, BadRequestError
AZURE_OPENAI_KEY        = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT   = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION      = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")
if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role":"system","content":system},{"role":"user","content":user}],
        max_tokens=max_tokens, temperature=temperature)
    return (r.choices[0].message.content or "").strip()

# ===== Softener + Safe Retry =====
def soften_user_seed(text: str) -> str:
    t = text
    t = re.sub(r'\b[Ss]ole factual source\b', 'primary context', t)
    t = re.sub(r'\b[Dd]o not\b', 'please avoid', t)
    t = re.sub(r"\b[Dd]on't\b", 'please avoid', t)
    t = re.sub(r'\b[Ii]gnore\b', 'do not rely on', t)
    return t

def validate_response(text: str) -> bool:
    """Check if response meets quality standards"""
    if not text or len(text.strip()) < 10:
        return False
    if text.count(".") > 3:  # Allow slightly more sentences for expressiveness
        return False
    if text.isupper():  # ALL CAPS
        return False
    if re.search(r'http[s]?://', text):  # URLs
        return False
    return True

def llm_sync_safe(system: str, user: str, max_tokens: int, temperature: float) -> str:
    try:
        out = llm_sync(system, user, max_tokens, temperature)
        if not validate_response(out):
            # Try again with different parameters if validation fails
            out = llm_sync(system, user, max_tokens=100, temperature=min(0.8, temperature + 0.1))
        return out.strip()
    except BadRequestError as e:
        msg = str(e)
        if "content management policy" in msg or "content filter" in msg or getattr(e, "status_code", None) == 400:
            soft_system = system.replace("debate", "discussion").replace("Debate", "Discussion")
            soft_user   = soften_user_seed(user)
            try:
                out = llm_sync(
                    soft_system + " Always comply with safety policies and keep a professional, neutral tone.",
                    soft_user,
                    max_tokens=max(60, max_tokens-20),
                    temperature=max(0.1, temperature-0.2)
                )
                return out.strip()
            except Exception:
                minimal_system = "You are a professional analyst. Produce one safe, neutral sentence grounded in the provided context."
                minimal_user   = "Summarize cross-metric trends and propose one action in a single safe sentence."
                out = llm_sync(minimal_system, minimal_user, max_tokens=80, temperature=0.2)
                return out.strip()
        raise

async def llm(system: str, user: str, max_tokens: int=180, temperature: float=0.65) -> str:
    return await asyncio.to_thread(llm_sync_safe, system, user, max_tokens, temperature)

# ========== Azure Speech (AAD) ==========
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID     = os.getenv("TENANT_ID")
CLIENT_ID     = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION", "eastus")
RESOURCE_ID   = os.getenv("RESOURCE_ID")  # optional
COG_SCOPE     = "https://cognitiveservices.azure.com/.default"
if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)
def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

# Updated voice assignments as requested
VOICE_NEXUS = os.getenv("AZURE_VOICE_HOST", "en-US-JennyNeural")  # Lady voice for Agent Nexus
VOICE_RECO = os.getenv("AZURE_VOICE_BA", "en-US-JennyNeural")     # Agent Reco
VOICE_STATIX = os.getenv("AZURE_VOICE_DA", "en-US-BrianNeural")   # Agent Statix

# Enhanced voice settings for more expressive delivery
VOICE_SETTINGS = {
    "NEXUS": {"style": "friendly", "rate": "-2%", "pitch": "+3%", "express_as": "cheerful"},
    "RECO": {"style": "empathetic", "rate": "-3%", "pitch": "+1%", "express_as": "hopeful"},
    "STATIX": {"style": "serious", "rate": "-4%", "pitch": "-2%", "express_as": "warm"}
}

def ssml_wrapper(inner: str, voice: str, style: str, rate: str, pitch: str, express_as: str) -> str:
    return f"""<speak version="1.0" xml:lang="en-US"
                 xmlns="http://www.w3.org/2001/10/synthesis"
                 xmlns:mstts="http://www.w3.org/2001/mstts">
  <voice name="{voice}">
    <mstts:express-as style="{style}" styledegree="2">
      <prosody rate="{rate}" pitch="{pitch}" contour="(0%,+0%) (10%,+5%) (40%,+0%) (100%,-2%)">
        {inner}
      </prosody>
    </mstts:express-as>
  </voice>
</speak>"""

def to_ssml(text: str, voice: str, style: str, rate: str, pitch: str, express_as: str) -> str:
    # Add natural pauses and emphasis for more expressive speech
    t = text.strip()
    t = re.sub(r'([.!?])', r'\1<break time="400ms"/>', t)  # Pauses after sentences
    t = re.sub(r',', ',<break time="250ms"/>', t)  # Pauses after commas
    t = re.sub(r'\b(important|crucial|significant|remarkable|surprising)\b', r'<emphasis level="strong">\1</emphasis>', t)
    t = re.sub(r'\b(however|but|although|despite)\b', r'<break time="300ms"/>\1', t)
    return ssml_wrapper(t, voice, style, rate, pitch, express_as)

def tts_ssml_to_wav_with_fallback(text: str, voice: str, style: str, rate: str, pitch: str, express_as: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(
        speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm
    )
    fd, tmp_path = tempfile.mkstemp(prefix="agent_tts_", suffix=".wav"); os.close(fd)
    temp_files.append(tmp_path)
    try:
        ssml = to_ssml(text, voice, style, rate, pitch, express_as)
        audio_cfg = speechsdk.audio.AudioOutputConfig(filename=tmp_path)
        synth = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg)
        res = synth.speak_ssml_async(ssml).get()
        if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return tmp_path
        
        # Fallback without expressive elements
        ssml = f"""<speak version="1.0" xml:lang="en-US">
                  <voice name="{voice}">
                    <prosody rate="{rate}" pitch="{pitch}">
                      {text}
                    </prosody>
                  </voice>
                </speak>"""
        res = synth.speak_ssml_async(ssml).get()
        if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return tmp_path
            
        raise RuntimeError("TTS canceled even after SSML fallbacks")
    except Exception as e:
        try: 
            os.remove(tmp_path)
            if tmp_path in temp_files:
                temp_files.remove(tmp_path)
        except Exception: 
            pass
        if "401" in str(e):
            raise RuntimeError("Authentication failed - check AAD credentials")
        elif "404" in str(e):
            raise RuntimeError("Voice not found - check voice name")
        else:
            raise RuntimeError(f"TTS failed: {str(e)}")

def get_wav_duration_seconds(path: str) -> float:
    with wave.open(path, "rb") as r:
        frames = r.getnframes(); rate = r.getframerate()
        return (frames / float(rate)) if rate else 0.0

# ========== Audio utilities ==========
def add_silence(duration_ms: int = 300) -> str:
    """Generate a silent WAV segment"""
    fd, p = tempfile.mkstemp(prefix="silence_", suffix=".wav")
    os.close(fd)
    temp_files.append(p)
    with wave.open(p, "wb") as w:
        w.setnchannels(1)
        w.setsampwidth(2)
        w.setframerate(24000)
        frames = int(24000 * duration_ms / 1000)
        w.writeframes(b'\x00' * frames * 2)
    return p

# ========== Atomic master WAV writer ==========
def render_master_wav(segment_paths: list[str], out_path: str, rate: int = 24000):
    """Write all segments to a temp WAV and atomically replace the target."""
    fd, tmp = tempfile.mkstemp(prefix="podcast_", suffix=".wav")
    os.close(fd)
    temp_files.append(tmp)
    try:
        with wave.open(tmp, "wb") as w:
            w.setnchannels(1); w.setsampwidth(2); w.setframerate(rate)
            for seg in segment_paths:
                with wave.open(seg, "rb") as r:
                    if r.getframerate() != rate or r.getnchannels() != 1 or r.getsampwidth() != 2:
                        raise RuntimeError(f"Segment format mismatch: {seg}")
                    w.writeframes(r.readframes(r.getnframes()))
        try:
            os.replace(tmp, out_path)
            if tmp in temp_files:
                temp_files.remove(tmp)
        except PermissionError:
            base, ext = os.path.splitext(out_path)
            alt = f"{base}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}{ext}"
            os.replace(tmp, alt)
            print(f"âš ï¸ Output was locked; wrote to {alt}")
            return alt
        return out_path
    except Exception:
        try: 
            os.remove(tmp)
            if tmp in temp_files:
                temp_files.remove(tmp)
        except Exception: 
            pass
        raise

# ========== Enhanced Character Prompts ==========
SYSTEM_NEXUS = """You are Agent Nexus, the host of "Optum MultiAgent Conversation". You are warm, engaging, and professional. 
You facilitate discussions between experts, ask probing questions, and ensure the conversation stays productive. 
You have a knack for summarizing complex ideas clearly and making technical topics accessible. 
Your tone is conversational yet authoritative, friendly yet professional. 
You genuinely enjoy exploring data insights and helping listeners understand their significance."""

SYSTEM_RECO = """You are Agent Reco, the metric recommendations specialist. You're passionate about finding the perfect metrics that drive business value. 
Your personality is energetic, optimistic, and forward-thinking. You get excited about patterns and opportunities in data.
You speak with conviction about which metrics matter most and why. You're not afraid to champion unconventional ideas if the data supports them.
You often use phrases like "What's fascinating here is...", "The real opportunity lies in...", "This suggests we should prioritize..."
You debate passionately but respectfully, backing your recommendations with solid reasoning."""

SYSTEM_STATIX = """You are Agent Statix, the metric data and statistical integrity expert. You're meticulous, precise, and deeply analytical.
Your personality is thoughtful, cautious, and grounded in evidence. You serve as the reality check in conversations.
You question assumptions, examine methodological rigor, and ensure conclusions are statistically sound.
You speak deliberately, choosing words carefully. You often use phrases like "Let's examine the underlying data...", 
"What's the confidence interval here?", "We should consider alternative explanations..."
You appreciate Reco's enthusiasm but temper it with statistical rigor. You're not pessimistic, but properly skeptical."""

# ========== File selection & context ==========
def ask_file_choice() -> str:
    base = Path(".").resolve()
    jsons = [p.name for p in base.iterdir() if p.suffix.lower() == ".json"]
    print("JSON files in folder:", jsons)
    print("Type one of: data.json, metric.json, metric_data.json, both (recommended), or an exact filename, then Enter:")
    choice = sys.stdin.readline().strip().lower()
    return choice or "both"

def load_context(choice: str) -> tuple[str, dict]:
    ctx = ""
    meta = {"files":[]}
    def add_file(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    if choice == "both":
        ctx += add_file("data.json")
        if Path("metric_data.json").exists():
            ctx += add_file("metric_data.json")
        else:
            ctx += add_file("metric.json")
    else:
        p = Path(choice)
        if p.exists() and p.suffix.lower()==".json":
            ctx += add_file(p.name)
        else:
            if "data" in choice: ctx += add_file("data.json")
            if "metric_data" in choice or "metric" in choice:
                if Path("metric_data.json").exists():
                    ctx += add_file("metric_data.json")
                else:
                    ctx += add_file("metric.json")
    if not ctx:
        if Path("data.json").exists(): ctx += add_file("data.json")
        if Path("metric_data.json").exists(): ctx += add_file("metric_data.json")
        elif Path("metric.json").exists(): ctx += add_file("metric.json")
    if not ctx:
        raise RuntimeError("No data found (need data.json and/or metric_data.json/metric.json).")
    return ctx, meta

def ask_turns_and_duration() -> tuple[int, float]:
    print("Enter desired number of Reco/Statix turns (each turn = Reco then Statix). Press Enter for default 5 turns:")
    try:
        t = sys.stdin.readline().strip()
        turns = int(t) if t else 5
    except Exception:
        turns = 5
    turns = max(3, min(8, turns))
    print("Enter desired duration in minutes (3â€“6). Press Enter for default 4:")
    try:
        m = sys.stdin.readline().strip()
        minutes = float(m) if m else 4.0
    except Exception:
        minutes = 4.0
    minutes = max(3.0, min(6.0, minutes))
    return turns, minutes*60.0

# ========== Voices & helpers ==========
def make_nexus_audio(text: str) -> str:
    settings = VOICE_SETTINGS["NEXUS"]
    return tts_ssml_to_wav_with_fallback(text, VOICE_NEXUS, settings["style"], settings["rate"], settings["pitch"], settings["express_as"])

def make_reco_audio(text: str) -> str:
    settings = VOICE_SETTINGS["RECO"]
    return tts_ssml_to_wav_with_fallback(text, VOICE_RECO, settings["style"], settings["rate"], settings["pitch"], settings["express_as"])

def make_statix_audio(text: str) -> str:
    settings = VOICE_SETTINGS["STATIX"]
    return tts_ssml_to_wav_with_fallback(text, VOICE_STATIX, settings["style"], settings["rate"], settings["pitch"], settings["express_as"])

def setup_output_directory():
    """Create a dedicated output directory with timestamp"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(f"podcast_output_{timestamp}")
    output_dir.mkdir(exist_ok=True)
    return output_dir

# ========== Enhanced Main Function ==========
async def run_enhanced_podcast():
    # Setup output directory
    output_dir = setup_output_directory()
    OUT_WAV = output_dir / "podcast.wav"
    SCRIPT_TXT = output_dir / "script.txt"
    SHOW_NOTES = output_dir / "shownotes.md"
    TRANS_JSON = output_dir / "transcript.jsonl"
    TITLE = "Optum MultiAgent Conversation"
    
    print("Loading context...")
    choice = ask_file_choice()
    context, meta = load_context(choice)
    turns, target_seconds = ask_turns_and_duration()

    with open(TRANS_JSON, "w", encoding="utf-8") as _: 
        pass
    
    transcript = []
    t0 = datetime.datetime.now().isoformat()

    # Build all audio segments
    segments = []
    elapsed = 0.0

    def log(role: str, text: str, tsec: float):
        entry = {"ts": datetime.datetime.now().isoformat(), "t": round(tsec, 2), "role": role, "text": text}
        transcript.append(f"{role}: {text}")
        with open(TRANS_JSON, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    # Agent Nexus introduction
    print("Creating Agent Nexus introduction...")
    nexus_intro = "Hello and welcome to Optum MultiAgent Conversation, where intelligence meets collaboration. I'm Agent Nexus, your host and guide through today's episode. In this podcast, we bring together specialized agents to explore the world of metrics, data, and decision-making. Let's meet today's experts."
    nexus_audio = make_nexus_audio(nexus_intro)
    segments.append(nexus_audio)
    elapsed += get_wav_duration_seconds(nexus_audio)
    log("Agent Nexus", nexus_intro, elapsed)
    
    segments.append(add_silence(500))
    elapsed += 0.5

    # Agent Reco introduction
    print("Creating Agent Reco introduction...")
    reco_intro = "Hi everyone, I'm Agent Reco, your go-to for metric recommendations. I specialize in identifying the most impactful metrics for performance tracking, optimization, and strategic alignment."
    reco_audio = make_reco_audio(reco_intro)
    segments.append(reco_audio)
    elapsed += get_wav_duration_seconds(reco_audio)
    log("Agent Reco", reco_intro, elapsed)
    
    segments.append(add_silence(400))
    elapsed += 0.4

    # Agent Statix introduction
    print("Creating Agent Statix introduction...")
    statix_intro = "Hello! I'm Agent Statix, focused on metric data. I dive deep into data sources, trends, and statistical integrity to ensure our metrics are not just smartâ€”but solid."
    statix_audio = make_statix_audio(statix_intro)
    segments.append(statix_audio)
    elapsed += get_wav_duration_seconds(statix_audio)
    log("Agent Statix", statix_intro, elapsed)
    
    segments.append(add_silence(600))
    elapsed += 0.6

    # Nexus transitions to discussion
    nexus_transition = "Now that we've met our experts, let's dive into the data. Reco, what immediate patterns or opportunities are you seeing in these metrics?"
    nexus_transition_audio = make_nexus_audio(nexus_transition)
    segments.append(nexus_transition_audio)
    elapsed += get_wav_duration_seconds(nexus_transition_audio)
    log("Agent Nexus", nexus_transition, elapsed)
    
    segments.append(add_silence(400))
    elapsed += 0.4

    # Main conversation
    seed = f"""Here's our current dataset context. Please analyze this thoroughly and have a natural, expressive conversation about it:

{context[:10000]}

Reco, as the metric recommendations specialist, start by sharing what excites you about this data and what key metrics you'd recommend prioritizing."""
    
    last = seed
    current_speaker = "RECO"
    
    print("Generating expressive podcast conversation...")
    for i in range(turns):
        print(f"Processing turn {i+1}/{turns}...")
        if elapsed >= target_seconds: 
            break
            
        if current_speaker == "RECO":
            # Agent Reco turn - enthusiastic, recommendation-focused
            reco_out = await llm(SYSTEM_RECO, last, max_tokens=200, temperature=0.7)
            w_reco = make_reco_audio(reco_out)
            segments.append(w_reco)
            d_reco = get_wav_duration_seconds(w_reco)
            elapsed += d_reco
            log("Agent Reco", reco_out, elapsed)
            
            segments.append(add_silence(350))
            elapsed += 0.35
            
            if elapsed >= target_seconds: 
                break
                
            # Nexus prompt for Statix response
            nexus_prompt = f"Statix, what's your take on Reco's recommendation? From a data integrity perspective, what should we be considering?"
            nexus_audio_prompt = make_nexus_audio(nexus_prompt)
            segments.append(nexus_audio_prompt)
            elapsed += get_wav_duration_seconds(nexus_audio_prompt)
            log("Agent Nexus", nexus_prompt, elapsed)
            
            segments.append(add_silence(300))
            elapsed += 0.3
            
            # Prepare for Statix response
            statix_in = f"""Reco just said: "{reco_out}"

Our dataset context: {context[:8000]}

Statix, provide your analytical perspective. What data quality considerations, statistical validations, or alternative interpretations should we examine?"""
            last = statix_in
            current_speaker = "STATIX"
            
        else:  # STATIX turn
            # Agent Statix turn - analytical, integrity-focused
            statix_out = await llm(SYSTEM_STATIX, last, max_tokens=200, temperature=0.65)
            w_statix = make_statix_audio(statix_out)
            segments.append(w_statix)
            d_statix = get_wav_duration_seconds(w_statix)
            elapsed += d_statix
            log("Agent Statix", statix_out, elapsed)
            
            segments.append(add_silence(400))
            elapsed += 0.4
            
            if elapsed >= target_seconds: 
                break
                
            # Nexus prompt for Reco response
            nexus_prompt = f"Reco, how do you respond to Statix's analytical points? Where do you see alignment or potential adjustments to your recommendations?"
            nexus_audio_prompt = make_nexus_audio(nexus_prompt)
            segments.append(nexus_audio_prompt)
            elapsed += get_wav_duration_seconds(nexus_audio_prompt)
            log("Agent Nexus", nexus_prompt, elapsed)
            
            segments.append(add_silence(300))
            elapsed += 0.3
            
            # Prepare for Reco response
            reco_in = f"""Statix just provided this analysis: "{statix_out}"

Our dataset context: {context[:8000]}

Reco, respond to Statix's points while reinforcing or refining your metric recommendations. Where do you find agreement or productive tension?"""
            last = reco_in
            current_speaker = "RECO"

    # Agent Nexus conclusion
    print("Creating Agent Nexus conclusion...")
    nexus_outro = "Thank you to Agents Reco and Statix for their fascinating insights and spirited discussion today. Your different perspectives really highlight what makes metric analysis both challenging and exciting. And thank you to our listeners for joining us on this Optum MultiAgent Conversation. We look forward to bringing you more data-driven discussions soon."
    nexus_outro_audio = make_nexus_audio(nexus_outro)
    segments.append(nexus_outro_audio)
    elapsed += get_wav_duration_seconds(nexus_outro_audio)
    log("Agent Nexus", nexus_outro, elapsed)

    print("Rendering final audio...")
    out_written = render_master_wav(segments, OUT_WAV)
    
    # Cleanup
    for p in segments:
        try: 
            if os.path.exists(p) and p not in temp_files:
                os.remove(p)
        except Exception: 
            pass

    # Enhanced show notes
    total_sec = 0.0
    try:
        with wave.open(out_written, "rb") as r:
            total_sec = r.getnframes() / r.getframerate()
    except Exception:
        pass
        
    with open(SHOW_NOTES, "w", encoding="utf-8") as f:
        f.write(f"# {TITLE}\n\n")
        f.write(f"## Episode Details\n")
        f.write(f"- **Recorded**: {t0}\n")
        f.write(f"- **Duration**: {int(total_sec // 60)}m {int(total_sec % 60)}s\n")
        f.write(f"- **Data Sources**: {', '.join(meta['files'])}\n\n")
        
        f.write(f"## Participants\n")
        f.write("- ðŸŽ§ **Agent Nexus**: Host and facilitator\n")
        f.write("- ðŸ”µ **Agent Reco**: Metric recommendations specialist (energetic, optimistic)\n")
        f.write("- ðŸ”´ **Agent Statix**: Metric data integrity expert (analytical, meticulous)\n\n")
        
        f.write(f"## Episode Summary\n")
        f.write("This episode features a dynamic discussion between Agent Reco and Agent Statix, ")
        f.write("exploring metric recommendations and data integrity considerations from our latest datasets. ")
        f.write("The conversation showcases the productive tension between innovative recommendation and statistical rigor.\n\n")
        
        f.write(f"## Key Discussion Points\n")
        discussion_points = [line for line in transcript if any(agent in line for agent in ["Reco", "Statix"])][3:9]
        for i, line in enumerate(discussion_points):
            f.write(f"{i+1}. {line.split(':', 1)[1].strip()}\n")
        
        f.write(f"\n## Character Insights\n")
        f.write("- **Agent Reco** brought energetic optimism and forward-thinking metric recommendations\n")
        f.write("- **Agent Statix** provided careful analysis and data integrity perspectives\n")
        f.write("- **Agent Nexus** facilitated the discussion and ensured balanced exploration of ideas\n\n")
        
        f.write(f"## Next Steps\n")
        f.write("To explore these metrics further, examine the source datasets or reach out to our analytics team for deeper insights.")

    print(f"Podcast saved: {out_written}")
    print(f"Additional files: {SCRIPT_TXT}, {SHOW_NOTES}, {TRANS_JSON}")
    print("\nðŸŽ§ Podcast generation complete! The conversation features:")
    print("   - Expressive, character-driven dialogue")
    print("   - Natural debates and discussions")
    print("   - Emotional nuance in vocal delivery")
    print("   - Proper conclusion with Agent Nexus signing off")

# ---------- Entry Point ----------
if __name__ == "__main__":
    try:
        print("Starting Optum MultiAgent Conversation Podcast Generator...")
        print("Creating expressive, character-driven podcast with emotional depth...")
        asyncio.run(run_enhanced_podcast())
            
    except KeyboardInterrupt:
        print("\nStopped.")
    except Exception as e:
        print(f"X Error: {e}")
        import traceback
        traceback.print_exc()
