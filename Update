# podcast_professional.py — Manager-ready: natural voices, no music, deep prompts, no repetition, atomic WAV
# pip install -U azure-cognitiveservices-speech azure-identity openai python-dotenv

import os, sys, re, math, wave, json, tempfile, asyncio, datetime, atexit, random
from pathlib import Path
from dotenv import load_dotenv; load_dotenv()

# -------------------- temp tracking & cleanup --------------------
temp_files: list[str] = []
@atexit.register
def _cleanup():
    for p in list(temp_files):
        try:
            if os.path.exists(p):
                os.remove(p)
        except Exception:
            pass

# -------------------- Azure OpenAI (safe + anti-repetition support) --------------------
from openai import AzureOpenAI, BadRequestError

AZURE_OPENAI_KEY        = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT   = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION      = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")
if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role":"system","content":system},{"role":"user","content":user}],
        max_tokens=max_tokens,
        temperature=temperature,
        top_p=0.85
    )
    return (r.choices[0].message.content or "").strip()

def soften_user_seed(text: str) -> str:
    t = text
    t = re.sub(r'\b[Ss]ole factual source\b', 'primary context', t)
    t = re.sub(r'\b[Dd]o not\b', 'please avoid', t)
    t = re.sub(r"\b[Dd]on't\b", 'please avoid', t)
    t = re.sub(r'\b[Ii]gnore\b', 'do not rely on', t)
    t = t.replace("debate", "discussion").replace("Debate", "Discussion")
    return t

def one_sentence_only(text: str) -> str:
    t = text.strip()
    t = re.sub(r'[`*_#>]+', ' ', t)
    t = re.sub(r'\s{2,}', ' ', t).strip()
    parts = re.split(r'(?<=[.!?])\s+', t)
    for p in parts:
        p = p.strip()
        if p:
            if len(p.split()) > 30:
                words = p.split()
                p = " ".join(words[:28]) + "…"
            return p
    return t

def validate_response(text: str) -> bool:
    if not text or len(text.strip()) < 10: return False
    if text.count(".") > 2: return False
    if text.isupper(): return False
    if re.search(r'http[s]?://', text): return False
    return True

def llm_sync_safe(system: str, user: str, max_tokens: int, temperature: float) -> str:
    try:
        out = llm_sync(system, user, max_tokens, temperature)
        if not validate_response(out):
            out = llm_sync(system, user, max_tokens=100, temperature=min(0.8, temperature + 0.1))
        return one_sentence_only(out)
    except BadRequestError as e:
        msg = str(e)
        if ("content management policy" in msg) or ("content filter" in msg) or getattr(e, "status_code", None) == 400:
            soft_system = system.replace("debate", "discussion").replace("Debate", "Discussion")
            soft_user   = soften_user_seed(user)
            try:
                out = llm_sync(
                    soft_system + " Always comply with safety policies and keep a professional, neutral tone.",
                    soft_user,
                    max_tokens=max(60, max_tokens-20),
                    temperature=max(0.1, temperature-0.2)
                )
                return one_sentence_only(out)
            except Exception:
                minimal_system = "You are a professional analyst. Produce one safe, neutral sentence grounded in the provided context."
                minimal_user   = "Summarize cross-metric trends and propose one action in a single safe sentence."
                out = llm_sync(minimal_system, minimal_user, max_tokens=80, temperature=0.2)
                return one_sentence_only(out)
        raise

async def llm(system: str, user: str, max_tokens: int=120, temperature: float=0.45) -> str:
    return await asyncio.to_thread(llm_sync_safe, system, user, max_tokens, temperature)

# -------------------- Azure Speech (AAD) --------------------
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID     = os.getenv("TENANT_ID")
CLIENT_ID     = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION", "eastus")
RESOURCE_ID   = os.getenv("RESOURCE_ID")  # optional
COG_SCOPE     = "https://cognitiveservices.azure.com/.default"
if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)
def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

# Voices per manager:
# - Nexus: distinct FEMALE host (NOT Jenny). Use Aria by default; override via AZURE_VOICE_HOST.
# - Reco: Jenny (female).
# - Statix: Brian (male).
VOICE_NEXUS  = os.getenv("AZURE_VOICE_HOST", "en-US-AriaNeural")
VOICE_RECO   = os.getenv("AZURE_VOICE_BA",   "en-US-JennyNeural")
VOICE_STATIX = os.getenv("AZURE_VOICE_DA",   "en-US-BrianNeural")

VOICE_SETTINGS = {
    "NEXUS":  {"style": "newscast-casual", "rate": "-5%", "pitch": "+2%"},
    "RECO":   {"style": "friendly",        "rate": "-6%", "pitch": "+1%"},
    "STATIX": {"style": "serious",         "rate": "-6%", "pitch": "-1%"},
}

def ssml_wrapper(inner: str, voice: str, style: str | None, rate: str, pitch: str) -> str:
    if style:
        return f"""<speak version="1.0" xml:lang="en-US"
                 xmlns="http://www.w3.org/2001/10/synthesis"
                 xmlns:mstts="http://www.w3.org/2001/mstts">
  <voice name="{voice}">
    <mstts:express-as style="{style}">
      <prosody rate="{rate}" pitch="{pitch}">
        {inner}
      </prosody>
    </mstts:express-as>
  </voice>
</speak>"""
    return f"""<speak version="1.0" xml:lang="en-US"
                 xmlns="http://www.w3.org/2001/10/synthesis">
  <voice name="{voice}">
    <prosody rate="{rate}" pitch="{pitch}">
      {inner}
    </prosody>
  </voice>
</speak>"""

def to_ssml(text: str, voice: str, style: str | None, rate: str = "-6%", pitch: str = "0%") -> str:
    # relaxed pacing (pauses after commas + tail pause)
    t = text.strip().replace(",", ",<break time='220ms'/>")
    inner = f"{t}<break time='320ms'/>"
    return ssml_wrapper(inner, voice, style, rate, pitch)

def tts_ssml_to_wav_with_fallback(text: str, voice: str, style: str | None, rate: str, pitch: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)
    fd, tmp_path = tempfile.mkstemp(prefix="seg_", suffix=".wav"); os.close(fd); temp_files.append(tmp_path)
    try:
        try_styles = [style, None] if style else [None]
        for sty in try_styles:
            ssml = to_ssml(text, voice, sty, rate, pitch)
            audio_cfg = speechsdk.audio.AudioOutputConfig(filename=tmp_path)
            synth = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg)
            res = synth.speak_ssml_async(ssml).get()
            if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                return tmp_path
        # plain text fallback
        audio_cfg = speechsdk.audio.AudioOutputConfig(filename=tmp_path)
        synth = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg)
        res = synth.speak_text_async(text).get()
        if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return tmp_path
        raise RuntimeError("TTS canceled even after SSML/style fallbacks")
    except Exception as e:
        try:
            if os.path.exists(tmp_path): os.remove(tmp_path)
        except Exception: pass
        if "401" in str(e):   raise RuntimeError("Authentication failed - check AAD credentials")
        if "404" in str(e):   raise RuntimeError("Voice not found - check voice name")
        raise RuntimeError(f"TTS failed: {str(e)}")

def get_wav_duration_seconds(path: str) -> float:
    with wave.open(path, "rb") as r:
        frames = r.getnframes(); rate = r.getframerate()
        return (frames / float(rate)) if rate else 0.0

def add_silence(duration_ms: int = 300) -> str:
    fd, p = tempfile.mkstemp(prefix="sil_", suffix=".wav"); os.close(fd); temp_files.append(p)
    with wave.open(p, "wb") as w:
        w.setnchannels(1); w.setsampwidth(2); w.setframerate(24000)
        frames = int(24000 * duration_ms / 1000)
        w.writeframes(b'\x00' * frames * 2)
    return p

# -------------------- Atomic render (prevents Wave_write attr errors) --------------------
def render_master_wav(segment_paths: list[str], out_path: str, rate: int = 24000) -> str:
    fd, tmp = tempfile.mkstemp(prefix="podcast_", suffix=".wav"); os.close(fd); temp_files.append(tmp)
    try:
        with wave.open(tmp, "wb") as w:
            w.setnchannels(1); w.setsampwidth(2); w.setframerate(rate)
            for seg in segment_paths:
                with wave.open(seg, "rb") as r:
                    if r.getframerate()!=rate or r.getnchannels()!=1 or r.getsampwidth()!=2:
                        raise RuntimeError(f"Segment format mismatch: {seg}")
                    w.writeframes(r.readframes(r.getnframes()))
        try:
            os.replace(tmp, out_path)
            if tmp in temp_files: temp_files.remove(tmp)
            return out_path
        except PermissionError:
            base, ext = os.path.splitext(out_path)
            alt = f"{base}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}{ext}"
            os.replace(tmp, alt)
            print(f"⚠️ Output was locked; wrote to {alt}")
            if tmp in temp_files: temp_files.remove(tmp)
            return alt
    except Exception:
        try:
            if os.path.exists(tmp): os.remove(tmp)
            if tmp in temp_files: temp_files.remove(tmp)
        except Exception: pass
        raise

# -------------------- Anti-filler & opener variety --------------------
FORBIDDEN_STARTERS = {
    "RECO":   {"absolutely","well","look","sure","okay","so","listen","hey","you know","hold on","right","great point"},
    "STATIX": {"hold on","actually","well","look","so","right","okay","absolutely","you know","listen","wait"},
}
VARIED_OPENERS = {
    "RECO":   ["Building on that,","Given that signal,","From a prioritization angle,","Operationally,","For outcomes,",
               "If we chase value first,","From a governance view,","For the roadmap,"],
    "STATIX": ["The data suggests","Quality checks imply","Trend consistency indicates","From variance patterns,",
               "Given sampling effects,","Month-to-month drift shows","On integrity grounds,","From historical bounds,"],
}
_last_opener_used = {"RECO": None, "STATIX": None}

def strip_leading_filler(text: str, role: str) -> str:
    t = text.strip()
    low = t.lower()
    low = re.sub(r'^(?:[a-z ]+,\s*)\1+', r'\1', low)  # dedupe repeated interjection
    for forb in sorted(FORBIDDEN_STARTERS.get(role, set()), key=len, reverse=True):
        if low.startswith(forb):
            cut = len(forb)
            t = t[cut:].lstrip(" ,–-")
            break
    return t.strip()

def diversify_opening(text: str, role: str) -> str:
    clean = strip_leading_filler(text, role)
    first_word = clean.split(" ", 1)[0].lower() if clean else ""
    if not clean or first_word in FORBIDDEN_STARTERS.get(role, set()):
        pool = VARIED_OPENERS[role][:]
        prev = _last_opener_used.get(role)
        if prev in pool: pool.remove(prev)
        opener = random.choice(pool) if pool else ""
        _last_opener_used[role] = opener
        clean = f"{opener} {clean}".strip() if opener else clean
    return re.sub(r'\s{2,}', ' ', clean).strip()

def humanize_line(text: str, role: str) -> str:
    s = one_sentence_only(text)
    s = diversify_opening(s, role)
    return s

# -------------------- Prompts (deeper roles; one sentence; reactive; non-repetitive) --------------------
SYSTEM_RECO = (
    "You are Agent Reco, a metrics recommendation specialist speaking with Agent Statix in a live, natural conversation. "
    "Speak in ONE concise sentence (≈15–25 words). Your sentence must: (1) respond directly to what Statix just said, "
    "(2) reference the datasets when helpful, (3) recommend a metric or action, (4) use varied, human phrasing. "
    "Hard rules: do NOT start with fillers or interjections like 'Absolutely', 'Well', 'Look', 'Sure', 'Okay', 'So', "
    "'Listen', 'Hey', 'You know', 'Hold on', 'Right', 'Great point'. Avoid repeating the same opener across turns. "
    "Use precise, concrete language; one idea per sentence; no lists, no hashtags, no file names."
)

SYSTEM_STATIX = (
    "You are Agent Statix, a metric data and statistical integrity expert responding to Agent Reco in a live, natural conversation. "
    "Speak in ONE concise sentence (≈15–25 words). Your sentence must: (1) respond explicitly to what Reco just said, "
    "(2) validate or challenge with a data-based rationale, (3) add one specific trend/quality check, (4) keep phrasing varied. "
    "Hard rules: do NOT start with fillers or interjections like 'Hold on', 'Actually', 'Well', 'Look', 'So', 'Right', "
    "'Okay', 'Absolutely', 'You know', 'Listen', 'Wait'. Avoid repeating the same opener across turns. "
    "Use precise, concrete language; one idea per sentence; no lists, no hashtags, no file names."
)

# Host (fixed manager lines; not generated)
HOST_INTRO = (
    "Hello and welcome to Optum MultiAgent Conversation, where intelligence meets collaboration. "
    "I’m Agent Nexus, your host and guide through today’s episode. In this podcast, we bring together specialized agents "
    "to explore the world of metrics, data, and decision-making. Let’s meet today’s experts."
)
HOST_OUTRO = (
    "Thank you to Agents Reco and Statix for their insights, and thank you to our listeners for joining us today."
)

# -------------------- File selection & context --------------------
def list_json_files() -> list[str]:
    return sorted([p.name for p in Path('.').iterdir() if p.suffix.lower()=='.json'])

def ask_file_choice() -> str:
    files = list_json_files()
    print("JSON files in folder:", files)
    print("Type one of: " + ", ".join(files + ["both"]) + ", then Enter:")
    choice = sys.stdin.readline().strip().lower()
    return choice or "both"

def load_context(choice: str) -> tuple[str, dict]:
    ctx = ""
    meta = {"files":[]}
    def add_file(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    files = list_json_files()
    if choice == "both":
        # if both, include all JSON files found (keeps it simple & future-proof)
        for f in files:
            ctx += add_file(f)
    else:
        # exact match or partial contains
        picked = None
        for f in files:
            if f.lower() == choice or Path(f).stem.lower() == choice:
                picked = f; break
        if not picked:
            # partial fallback
            for f in files:
                if choice in f.lower():
                    picked = f; break
        if picked:
            ctx += add_file(picked)
        else:
            # fallback: include all
            for f in files:
                ctx += add_file(f)
    if not ctx:
        raise RuntimeError("No .json files found in the current folder.")
    return ctx, meta

def ask_turns_and_duration() -> tuple[int, float]:
    print("Enter desired number of Reco/Statix turns (each turn = Reco then Statix). Press Enter for default 6 turns:")
    try:
        t = sys.stdin.readline().strip()
        turns = int(t) if t else 6
    except Exception:
        turns = 6
    turns = max(4, min(10, turns))
    print("Enter desired duration in minutes (2–5). Press Enter for default 3:")
    try:
        m = sys.stdin.readline().strip()
        minutes = float(m) if m else 3.0
    except Exception:
        minutes = 3.0
    minutes = max(2.0, min(5.0, minutes))
    return turns, minutes*60.0

# -------------------- Voice helpers --------------------
def make_audio(text: str, who: str, voice: str) -> str:
    s = VOICE_SETTINGS[who]
    return tts_ssml_to_wav_with_fallback(text, voice, s["style"], s["rate"], s["pitch"])

def make_nexus(text: str) -> str:
    return make_audio(text, "NEXUS", VOICE_NEXUS)

def make_reco(text: str) -> str:
    return make_audio(text, "RECO", VOICE_RECO)

def make_statix(text: str) -> str:
    return make_audio(text, "STATIX", VOICE_STATIX)

# -------------------- Output directory --------------------
def setup_output_directory() -> Path:
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    d = Path(f"podcast_output_{ts}")
    d.mkdir(exist_ok=True)
    return d

# -------------------- Main --------------------
async def run_podcast():
    outdir = setup_output_directory()
    OUT_WAV    = outdir / "podcast.wav"
    SCRIPT_TXT = outdir / "script.txt"
    SHOW_NOTES = outdir / "shownotes.md"
    TRANS_JSON = outdir / "transcript.jsonl"
    TITLE      = "Optum MultiAgent Conversation"

    files = list_json_files()
    print("Loading context...")
    choice = ask_file_choice()
    context, meta = load_context(choice)
    turns, target_seconds = ask_turns_and_duration()

    # truncate transcript jsonl
    with open(TRANS_JSON, "w", encoding="utf-8") as _: pass
    transcript = []
    t0 = datetime.datetime.now().isoformat()

    segments: list[str] = []
    elapsed = 0.0

    def log(role: str, text: str, tsec: float):
        entry = {"ts": datetime.datetime.now().isoformat(), "t": round(tsec,2), "role": role, "text": text}
        transcript.append(f"{role}: {text}")
        with open(TRANS_JSON, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    # Host intro (manager’s exact wording)
    intro_audio = make_nexus(HOST_INTRO)
    segments.append(intro_audio); elapsed += get_wav_duration_seconds(intro_audio)
    log("Agent Nexus", HOST_INTRO, elapsed)

    # short pause
    segments.append(add_silence(500)); elapsed += 0.5

    # Agent intros (manager’s exact wording)
    reco_intro = ("Hi everyone, I’m Agent Reco, your go-to for metric recommendations. "
                  "I specialize in identifying the most impactful metrics for performance tracking, "
                  "optimization, and strategic alignment.")
    a_reco_intro = make_reco(reco_intro)
    segments.append(a_reco_intro); elapsed += get_wav_duration_seconds(a_reco_intro)
    log("Agent Reco", reco_intro, elapsed)

    segments.append(add_silence(400)); elapsed += 0.4

    statix_intro = ("Hello! I’m Agent Statix, focused on metric data. I dive deep into data sources, trends, "
                    "and statistical integrity to ensure our metrics are not just smart—but solid.")
    a_statix_intro = make_statix(statix_intro)
    segments.append(a_statix_intro); elapsed += get_wav_duration_seconds(a_statix_intro)
    log("Agent Statix", statix_intro, elapsed)

    # small settle
    segments.append(add_silence(600)); elapsed += 0.6

    # Seed (softened), deep yet safe
    seed = soften_user_seed(
        "Use these datasets as primary context; produce a natural one-sentence exchange per turn with varied, human phrasing. "
        "Reference concrete numbers/trends only when visible.\n" + context[:14000]
    )
    last = seed

    # Conversation loop (strict one sentence, non-repetitive, reactive)
    for i in range(turns):
        if elapsed >= target_seconds: break

        # Reco
        reco_raw = await llm(
            SYSTEM_RECO,
            soften_user_seed(
                "Reply in one sentence with varied, human phrasing; do not reuse your last opener or any filler. "
                f"Agent Statix previously said: {last if i>0 else 'N/A'}\n"
                f"Reference context (no need to name files):\n{context[:9000]}"
            ),
            max_tokens=120, temperature=0.45
        )
        reco_line = humanize_line(reco_raw, "RECO")
        seg = make_reco(reco_line); segments.append(seg)
        elapsed += get_wav_duration_seconds(seg)
        log("Agent Reco", reco_line, elapsed)

        segments.append(add_silence(320)); elapsed += 0.32
        if elapsed >= target_seconds: break

        # Statix
        statix_raw = await llm(
            SYSTEM_STATIX,
            soften_user_seed(
                "Reply in one sentence with varied, human phrasing; do not reuse your last opener or any filler. "
                f"Agent Reco just said: {reco_line}\n"
                f"Reference context (no need to name files):\n{context[:9000]}"
            ),
            max_tokens=120, temperature=0.45
        )
        statix_line = humanize_line(statix_raw, "STATIX")
        seg = make_statix(statix_line); segments.append(seg)
        elapsed += get_wav_duration_seconds(seg)
        log("Agent Statix", statix_line, elapsed)

        segments.append(add_silence(360)); elapsed += 0.36
        last = statix_line

    # Host outro (manager’s exact wording)
    outro_audio = make_nexus(HOST_OUTRO)
    segments.append(outro_audio); elapsed += get_wav_duration_seconds(outro_audio)
    log("Agent Nexus", HOST_OUTRO, elapsed)

    # Render atomically
    out_written = render_master_wav(segments, str(OUT_WAV))

    # cleanup segments (keep only final)
    for p in segments:
        try:
            if os.path.exists(p) and p not in temp_files:
                os.remove(p)
        except Exception:
            pass

    # Save script + notes
    with open(SCRIPT_TXT, "w", encoding="utf-8") as f:
        f.write("\n".join(transcript))

    total_sec = 0.0
    try:
        with wave.open(out_written, "rb") as r:
            total_sec = r.getnframes() / r.getframerate()
    except Exception:
        pass

    with open(SHOW_NOTES, "w", encoding="utf-8") as f:
        f.write(f"# {TITLE}\n\n")
        f.write(f"- **Recorded**: {t0}\n")
        f.write(f"- **Duration**: {int(total_sec // 60)}m {int(total_sec % 60)}s\n")
        f.write(f"- **Data sources**: {', '.join(meta['files'])}\n")
        f.write("\n## Participants\n")
        f.write("- 🎧 Agent Nexus (Host)\n- 🔵 Agent Reco (Recommendations)\n- 🔴 Agent Statix (Statistics)\n")
        f.write("\n## Format\n")
        f.write("- Host intro, agent intros, one-sentence turns with natural pacing, host outro (no music/jingles)\n")

    print(f"✅ Saved: {out_written}")
    print(f"📝 Also wrote: {SCRIPT_TXT}, {SHOW_NOTES}, {TRANS_JSON}")

# -------------------- entry --------------------
if __name__ == "__main__":
    try:
        print("Starting Optum MultiAgent Conversation Podcast Generator (no music)…")
        asyncio.run(run_podcast())
    except KeyboardInterrupt:
        print("\nStopped.")
    except Exception as e:
        print(f"X Error: {e}")
        import traceback; traceback.print_exc()
