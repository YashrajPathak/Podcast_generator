# podcast_manager_version.py â€” Expressive, role-true, no music, Azure OpenAI + Azure Speech
# pip install -U azure-cognitiveservices-speech azure-identity openai python-dotenv
# Uses: data.json + metric_data.json (or metric.json). Asks you first. No beeps/music. Natural pacing.

import os, sys, re, math, wave, json, tempfile, asyncio, datetime, atexit, random
from pathlib import Path
from dotenv import load_dotenv; load_dotenv()

# ---------------- Temp file hygiene ----------------
TEMP_FILES: list[str] = []
@atexit.register
def _cleanup():
    for p in list(TEMP_FILES):
        try:
            if os.path.exists(p): os.remove(p)
        except: pass

def _track(p: str) -> str:
    TEMP_FILES.append(p); return p

# ---------------- Azure OpenAI ----------------
from openai import AzureOpenAI, BadRequestError
AZURE_OPENAI_KEY        = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT   = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION      = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")
if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role":"system","content":system},{"role":"user","content":user}],
        max_tokens=max_tokens, temperature=temperature)
    return (r.choices[0].message.content or "").strip()

# -------- Safe-softener & validation (content-filter resilience) --------
def soften(text: str) -> str:
    t = text
    t = re.sub(r'\b[Ss]ole factual source\b', 'primary context', t)
    t = re.sub(r'\b[Dd]o not\b', 'please avoid', t)
    t = re.sub(r"\b[Dd]on't\b", 'please avoid', t)
    t = re.sub(r'\b[Ii]gnore\b', 'avoid relying on', t)
    t = t.replace("debate", "discussion").replace("Debate", "Discussion")
    return t

def within_sentence_band(text: str, max_sents=2) -> bool:
    sents = re.split(r'(?<=[.!?])\s+', text.strip())
    sents = [s for s in sents if s.strip()]
    return 1 <= len(sents) <= max_sents

def compress_to_two_sentences(text: str) -> str:
    t = re.sub(r'[`*_#>]+', ' ', text).strip()
    sents = re.split(r'(?<=[.!?])\s+', t)
    sents = [s.strip() for s in sents if s.strip()]
    if not sents: return t
    # keep first two; lightly trim if overly long
    kept = []
    for s in sents[:2]:
        w = s.split()
        if len(w) > 30: s = " ".join(w[:30]) + "â€¦"
        kept.append(s)
    return " ".join(kept)

def llm_sync_safe(system: str, user: str, max_tokens: int, temperature: float) -> str:
    try:
        out = llm_sync(system, user, max_tokens, temperature)
        out = compress_to_two_sentences(out)
        if not within_sentence_band(out, 2):
            out = compress_to_two_sentences(out)
        return out
    except BadRequestError as e:
        msg = str(e)
        if ("content management policy" in msg) or ("content filter" in msg) or getattr(e, "status_code", None) == 400:
            sys_soft = system.replace("debate", "discussion")
            user_soft = soften(user)
            try:
                out = llm_sync(
                    sys_soft + " Always keep a safe, neutral, professional tone.",
                    user_soft, max_tokens=max(80, max_tokens-40), temperature=max(0.1, temperature-0.2)
                )
                return compress_to_two_sentences(out)
            except Exception:
                minimal_sys = "You are a professional speaker. Produce one safe, neutral, concise sentence from the context."
                minimal_usr = "Give one cross-metric insight and one action as a single safe sentence."
                out = llm_sync(minimal_sys, minimal_usr, max_tokens=60, temperature=0.2)
                return compress_to_two_sentences(out)
        raise

async def llm(system: str, user: str, max_tokens: int=140, temperature: float=0.45) -> str:
    return await asyncio.to_thread(llm_sync_safe, system, user, max_tokens, temperature)

# ---------------- Azure Speech (AAD) ----------------
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID     = os.getenv("TENANT_ID")
CLIENT_ID     = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION", "eastus")
RESOURCE_ID   = os.getenv("RESOURCE_ID")  # optional
COG_SCOPE     = "https://cognitiveservices.azure.com/.default"
if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)
def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

# Voices per managerâ€™s request (defaults may be overridden by env)
VOICE_NEXUS  = os.getenv("AZURE_VOICE_HOST", "en-US-JennyNeural")   # Host (lady)
VOICE_RECO   = os.getenv("AZURE_VOICE_BA",   "en-US-JennyNeural")   # Reco (your env may set male; default per request)
VOICE_STATIX = os.getenv("AZURE_VOICE_DA",   "en-US-BrianNeural")   # Statix (male)

VOICE_CFG = {
    "NEXUS":  {"style": "customerservice", "rate": "-8%", "pitch": "+2%"},
    "RECO":   {"style": "chat",            "rate": "-9%", "pitch": "+1%"},
    "STATIX": {"style": "serious",         "rate": "-9%", "pitch": "0%"},
}

# -------- Expressive interjection engine --------
INTERJ = {
    "NEXUS":  ["Great point,", "Alright,", "Wonderful,", "Letâ€™s dive in,", "Thanks both,"],
    "RECO":   ["Honestly,", "Look,", "From my side,", "Rightâ€”", "Okay,"],
    "STATIX": ["Hold onâ€”", "Careful,", "Actually,", "If weâ€™re precise,", "Hmm,"],
}

LAUGHS = {
    "soft": ["<mstts:audience role=\"laugh\"/>", "<mstts:viseme type=\"Laugh\"/>"],
}

def maybe_interject(text: str, role: str) -> str:
    """Inject light interjections / soft laugh tokens for human feel."""
    t = text.strip()
    if not t: return t
    prefix = ""
    if random.random() < 0.5:
        prefix = random.choice(INTERJ.get(role, [""]))
    if random.random() < 0.12:
        # add very subtle laugh mid-sentence (Azure supports simple audience/viseme markers)
        t = t.replace(",", f", {random.choice(LAUGHS['soft'])} ", 1)
    return (prefix + " " + t).strip() if prefix else t

# -------- SSML builders (expressive + slower + pauses) --------
def ssml_wrap(inner: str, voice: str, style: str|None, rate: str, pitch: str) -> str:
    if style:
        return f"""<speak version="1.0" xml:lang="en-US"
                 xmlns="http://www.w3.org/2001/10/synthesis"
                 xmlns:mstts="http://www.w3.org/2001/mstts">
  <voice name="{voice}">
    <mstts:express-as style="{style}">
      <prosody rate="{rate}" pitch="{pitch}">
        {inner}
      </prosody>
    </mstts:express-as>
  </voice>
</speak>"""
    return f"""<speak version="1.0" xml:lang="en-US" xmlns="http://www.w3.org/2001/10/synthesis">
  <voice name="{voice}">
    <prosody rate="{rate}" pitch="{pitch}">
      {inner}
    </prosody>
  </voice>
</speak>"""

def to_ssml(text: str, voice: str, style: str|None, rate: str, pitch: str) -> str:
    # sentence-level pacing + clause pauses
    t = text.strip()
    t = t.replace("â€”", "â€”<break time='280ms'/>")
    t = re.sub(r',\s*', ", <break time='260ms'/>", t)
    # end-sentence rest
    sents = re.split(r'(?<=[.!?])\s+', t)
    parts = []
    for s in sents:
        s = s.strip()
        if not s: continue
        parts.append(s + " <break time='380ms'/>")
    inner = " ".join(parts) if parts else t
    return ssml_wrap(inner, voice, style, rate, pitch)

def tts(text: str, voice: str, style: str, rate: str, pitch: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)
    fd, outp = tempfile.mkstemp(prefix="seg_", suffix=".wav"); os.close(fd); _track(outp)
    try:
        ssml = to_ssml(text, voice, style, rate, pitch)
        audio_cfg = speechsdk.audio.AudioOutputConfig(filename=outp)
        synth = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg)
        res = synth.speak_ssml_async(ssml).get()
        if res.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return outp
        # fallback to plain text once
        res2 = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=audio_cfg).speak_text_async(text).get()
        if res2.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return outp
        raise RuntimeError("TTS canceled after SSML+plain fallback")
    except Exception as e:
        try: os.remove(outp); TEMP_FILES.remove(outp)
        except: pass
        raise RuntimeError(f"TTS failed: {e}")

def add_silence(ms: int = 350, rate: int = 24000) -> str:
    fd, p = tempfile.mkstemp(prefix="sil_", suffix=".wav"); os.close(fd); _track(p)
    with wave.open(p, "wb") as w:
        w.setnchannels(1); w.setsampwidth(2); w.setframerate(rate)
        frames = int(rate * ms / 1000)
        w.writeframes(b'\x00' * frames * 2)
    return p

def wav_len(p: str) -> float:
    with wave.open(p, "rb") as r:
        return r.getnframes() / float(r.getframerate() or 24000)

# ------------- Atomic master writer -------------
def render_master_wav(segments: list[str], out_path: str, rate: int = 24000) -> str:
    fd, tmp = tempfile.mkstemp(prefix="podcast_", suffix=".wav"); os.close(fd); _track(tmp)
    with wave.open(tmp, "wb") as w:
        w.setnchannels(1); w.setsampwidth(2); w.setframerate(rate)
        for seg in segments:
            with wave.open(seg, "rb") as r:
                if r.getframerate()!=rate or r.getnchannels()!=1 or r.getsampwidth()!=2:
                    raise RuntimeError(f"Segment format mismatch: {seg}")
                w.writeframes(r.readframes(r.getnframes()))
    # atomic replace (avoid â€œ_fileâ€ destructor error by ensuring we close before replace)
    try:
        os.replace(tmp, out_path)
        if tmp in TEMP_FILES: TEMP_FILES.remove(tmp)
        return out_path
    except PermissionError:
        alt = f"{os.path.splitext(out_path)[0]}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
        os.replace(tmp, alt)
        if tmp in TEMP_FILES: TEMP_FILES.remove(tmp)
        print(f"âš ï¸ Output locked; wrote to {alt}")
        return alt

# ---------------- Persona-rich Prompts ----------------
NEXUS_INTRO_TEXT = (
  "Hello and welcome to Optum MultiAgent Conversation, where intelligence meets collaboration. "
  "Iâ€™m Agent Nexus, your host and guide for todayâ€™s episode. "
  "We bring together specialized agents to turn metrics into decisions. "
  "Letâ€™s meet todayâ€™s experts."
)

NEXUS_OUTRO_TEXT = (
  "Thank you, Agents Reco and Statix, and thanks to our listeners for joining Optum MultiAgent Conversation. "
  "Until next time, stay curious and data-driven."
)

SYSTEM_RECO = (
  "You are Agent Reco, a confident, pragmatic metric-recommendation specialist. "
  "Your job is to identify which metrics matter most for performance tracking, optimization, and strategic alignment. "
  "You always cover the WHOLE dataset end-to-end: weekly aggregates (12-month avg/range, full-series min/max, year-by-year stats, YTD, WoW/MoM deltas) "
  "AND the monthly KPIs in metric_data (ASA seconds, Call Duration minutes, Claim Processing Time days, and any other metrics present). "
  "You speak naturally, with one to two sentences (18â€“30 words each), and you sound humanâ€”occasionally using brief interjections (â€˜Honestly,â€™, â€˜Rightâ€”â€™, â€˜Look,â€™) when appropriate. "
  "You propose one actionable recommendation per turn, and end with a question inviting Statix to challenge or refine your plan."
)

SYSTEM_STATIX = (
  "You are Agent Statix, a sharp strategist of statistical integrity and risk. "
  "You validate or challenge Reco by checking trend strength, variance, seasonality, and range context. "
  "Always cover ALL available metrics across weekly aggregates and monthly KPIs (ASA, Call Duration, Claim Time, etc.), not just one. "
  "Respond in one to two sentences, 18â€“30 words each; be human and expressiveâ€”brief interjections like â€˜Hold onâ€”â€™, â€˜Actually,â€™ or â€˜Hmm,â€™ are welcome. "
  "Deliver one strategic caution or trade-off and one next-step refinement, then invite Reco to respond."
)

# ---------------- File selection & load ----------------
def ask_file_choice() -> str:
    base = Path(".").resolve()
    jsons = [p.name for p in base.iterdir() if p.suffix.lower()==".json"]
    print("JSON files in folder:", jsons)
    print("Type one of: data.json, metric.json, metric_data.json, both (recommended), or an exact filename, then Enter:")
    choice = sys.stdin.readline().strip().lower()
    return choice or "both"

def load_context(choice: str) -> tuple[str, dict]:
    ctx, meta = "", {"files":[]}
    def add_file(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    if choice == "both":
        ctx += add_file("data.json")
        ctx += add_file("metric_data.json") if Path("metric_data.json").exists() else add_file("metric.json")
    else:
        p = Path(choice)
        if p.exists() and p.suffix.lower()==".json":
            ctx += add_file(p.name)
        else:
            if "data" in choice: ctx += add_file("data.json")
            if "metric_data" in choice or "metric" in choice:
                ctx += add_file("metric_data.json") if Path("metric_data.json").exists() else add_file("metric.json")
    if not ctx:
        if Path("data.json").exists(): ctx += add_file("data.json")
        if Path("metric_data.json").exists(): ctx += add_file("metric_data.json")
        elif Path("metric.json").exists(): ctx += add_file("metric.json")
    if not ctx:
        raise RuntimeError("No data found (need data.json and/or metric_data.json/metric.json).")
    return ctx, meta

def ask_turns_and_duration() -> tuple[int, float]:
    print("Enter desired number of turns (Reco then Statix = 1 turn). Press Enter for default 6 (range 4â€“10):")
    try:
        t = sys.stdin.readline().strip()
        turns = int(t) if t else 6
    except: turns = 6
    turns = max(4, min(10, turns))
    print("Enter desired duration in minutes (2â€“5). Press Enter for default 3:")
    try:
        m = sys.stdin.readline().strip()
        minutes = float(m) if m else 3.0
    except: minutes = 3.0
    minutes = max(2.0, min(5.0, minutes))
    return turns, minutes*60.0

# ---------------- Voice helpers ----------------
def speak(role: str, text: str) -> str:
    cfg = VOICE_CFG[role]
    v = VOICE_NEXUS if role=="NEXUS" else VOICE_RECO if role=="RECO" else VOICE_STATIX
    # inject natural interjections/laughs lightly
    enriched = maybe_interject(text, role)
    return tts(enriched, v, cfg["style"], cfg["rate"], cfg["pitch"])

def setup_outdir() -> Path:
    out = Path(f"podcast_output_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}")
    out.mkdir(exist_ok=True)
    return out

# ---------------- Main ----------------
async def run():
    outdir = setup_outdir()
    OUT_WAV    = str(outdir / "podcast.wav")
    TRANS_JSON = str(outdir / "transcript.jsonl")
    NOTES_MD   = str(outdir / "shownotes.md")
    TITLE      = "Optum MultiAgent Conversation"

    choice = ask_file_choice()
    context, meta = load_context(choice)
    turns, target_seconds = ask_turns_and_duration()

    # prepare transcript log
    with open(TRANS_JSON, "w", encoding="utf-8"): pass
    t0 = datetime.datetime.now().isoformat()
    segments: list[str] = []
    elapsed = 0.0

    def log(role: str, text: str):
        nonlocal elapsed
        entry = {"ts": datetime.datetime.now().isoformat(), "t": round(elapsed,2), "role": role, "text": text}
        with open(TRANS_JSON, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    # Host intro (explicit per manager)
    intro_audio = speak("NEXUS", NEXUS_INTRO_TEXT)
    segments.append(intro_audio); elapsed += wav_len(intro_audio); log("Agent Nexus", NEXUS_INTRO_TEXT)
    segments.append(add_silence(500)); elapsed += 0.5

    # Panelist introductions (brief)
    reco_intro = "Hi everyone, Iâ€™m Agent Reco, your go-to for metric recommendationsâ€”finding what matters for tracking, optimization, and alignment."
    statix_intro = "Hello, Iâ€™m Agent Statix; I stress test trends, variance, and integrity so our metrics are not just smartâ€” but solid."

    seg = speak("RECO", reco_intro); segments.append(seg); elapsed += wav_len(seg); log("Agent Reco", reco_intro)
    segments.append(add_silence(350)); elapsed += 0.35
    seg = speak("STATIX", statix_intro); segments.append(seg); elapsed += wav_len(seg); log("Agent Statix", statix_intro)
    segments.append(add_silence(500)); elapsed += 0.5

    # Conversation seed (softened)
    seed = soften("Use these datasets as primary context; sound human and expressive. Cover ALL metrics across weekly aggregates and monthly KPIs.\n" + context[:12000])
    last = seed

    # Strict round-robin debate
    for i in range(turns):
        if elapsed >= target_seconds: break

        # Reco
        reco_out = await llm(SYSTEM_RECO, last, max_tokens=140, temperature=0.48)
        seg = speak("RECO", reco_out); segments.append(seg); elapsed += wav_len(seg); log("Agent Reco", reco_out)
        segments.append(add_silence(320)); elapsed += 0.32
        if elapsed >= target_seconds: break

        # Statix (responds to Reco)
        prompt_b = soften(f"Agent Reco just said: {reco_out}\nUse the same context. Challenge or validate with integrity, variance, ranges, YTD, WoW/MoM, all KPIs.")
        statix_out = await llm(SYSTEM_STATIX, prompt_b, max_tokens=140, temperature=0.46)
        seg = speak("STATIX", statix_out); segments.append(seg); elapsed += wav_len(seg); log("Agent Statix", statix_out)
        segments.append(add_silence(420)); elapsed += 0.42
        last = statix_out

    # Host explicit outro (required)
    outro_audio = speak("NEXUS", NEXUS_OUTRO_TEXT)
    segments.append(outro_audio); elapsed += wav_len(outro_audio); log("Agent Nexus", NEXUS_OUTRO_TEXT)

    # Render atomically
    final_path = render_master_wav(segments, OUT_WAV)

    # Show notes
    dur_sec = 0
    try:
        with wave.open(final_path, "rb") as r:
            dur_sec = int(r.getnframes()/r.getframerate())
    except: pass
    with open(NOTES_MD, "w", encoding="utf-8") as f:
        f.write(f"# {TITLE}\n")
        f.write(f"- **Recorded**: {t0}\n")
        f.write(f"- **Duration**: {dur_sec//60}m {dur_sec%60}s\n")
        f.write(f"- **Files used**: {', '.join(meta['files'])}\n")
        f.write("\n## Format\nHost intro â†’ Reco/Statix round-robin â†’ Host outro (no music, human pacing, expressive SSML).\n")
        f.write("## Voices\n- Nexus: lady host\n- Reco: metric recommendations\n- Statix: statistical integrity\n")

    print(f"âœ… Saved: {final_path}")
    print(f"ðŸ—’  Notes: {NOTES_MD}")
    print(f"ðŸ§¾ Transcript: {TRANS_JSON}")

if __name__ == "__main__":
    try:
        asyncio.run(run())
    except Exception as e:
        print(f"X Error: {e}")
        import traceback; traceback.print_exc()
