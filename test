# podcast_fixed_openings.py — Exact scripted openings/closings + humanlike one-sentence discussion
# No music/beeps. Azure OpenAI + Azure Speech.
# pip install -U azure-cognitiveservices-speech azure-identity openai python-dotenv

import os, sys, re, wave, json, tempfile, asyncio, datetime, random, atexit
from pathlib import Path
from dotenv import load_dotenv; load_dotenv()

# ------------------------- temp tracking & cleanup -------------------------
TMP: list[str] = []
@atexit.register
def _cleanup():
    for p in TMP:
        try:
            if os.path.exists(p): os.remove(p)
        except Exception: pass

# ------------------------- Azure OpenAI (safe) -----------------------------
from openai import AzureOpenAI, BadRequestError
AZURE_OPENAI_KEY        = os.getenv("AZURE_OPENAI_KEY") or os.getenv("OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT   = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o")
OPENAI_API_VERSION      = os.getenv("OPENAI_API_VERSION", "2024-05-01-preview")
if not all([AZURE_OPENAI_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, OPENAI_API_VERSION]):
    raise RuntimeError("Missing Azure OpenAI env vars")

oai = AzureOpenAI(api_key=AZURE_OPENAI_KEY, azure_endpoint=AZURE_OPENAI_ENDPOINT, api_version=OPENAI_API_VERSION)

def _llm_sync(system: str, user: str, max_tokens: int, temperature: float) -> str:
    r = oai.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=[{"role":"system","content":system},{"role":"user","content":user}],
        max_tokens=max_tokens, temperature=temperature)
    return (r.choices[0].message.content or "").strip()

def _soften(text: str) -> str:
    t = text
    t = re.sub(r'\b[Ss]ole factual source\b','primary context', t)
    t = re.sub(r'\b[Dd]o not\b','please avoid', t)
    t = re.sub(r"\b[Dd]on't\b",'please avoid', t)
    t = re.sub(r'\b[Ii]gnore\b','do not rely on', t)
    t = t.replace("debate","discussion").replace("Debate","Discussion")
    return t

def _one_sentence(text: str, max_words: int = 26) -> str:
    t = re.sub(r'[`*_#>]+',' ', text).strip()
    t = re.sub(r'\s{2,}',' ', t)
    s = (re.split(r'(?<=[.!?])\s+', t) or [t])[0].strip()
    words = s.split()
    return " ".join(words[:max_words-1]) + "…" if len(words)>max_words else s

def _looks_ok(text: str) -> bool:
    return bool(text and len(text.strip())>=8 and text.count(".")<=2 and not text.isupper() and not re.search(r'http[s]?://', text))

def llm_safe(system: str, user: str, max_tokens: int, temperature: float) -> str:
    try:
        out = _llm_sync(system, user, max_tokens, temperature)
        if not _looks_ok(out):
            out = _llm_sync(system, user, max_tokens=max(60, max_tokens//2), temperature=min(0.8, temperature+0.1))
        return _one_sentence(out)
    except BadRequestError as e:
        soft_sys = _soften(system) + " Always keep a professional, neutral tone and comply with safety policies."
        soft_user= _soften(user)
        try:
            out = _llm_sync(soft_sys, soft_user, max_tokens=max(60, max_tokens-20), temperature=max(0.1, temperature-0.2))
            return _one_sentence(out)
        except Exception:
            minimal_system = "You are a professional analyst; produce one safe, neutral sentence grounded in the provided context."
            minimal_user   = "Summarize cross-metric trends and propose one action in a single safe sentence."
            out = _llm_sync(minimal_system, minimal_user, max_tokens=80, temperature=0.2)
            return _one_sentence(out)

async def llm(system: str, user: str, max_tokens: int=110, temperature: float=0.45) -> str:
    return await asyncio.to_thread(llm_safe, system, user, max_tokens, temperature)

# ------------------------- Azure Speech (AAD) ------------------------------
import azure.cognitiveservices.speech as speechsdk
from azure.identity import ClientSecretCredential

TENANT_ID     = os.getenv("TENANT_ID")
CLIENT_ID     = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
SPEECH_REGION = os.getenv("SPEECH_REGION","eastus")
RESOURCE_ID   = os.getenv("RESOURCE_ID")
COG_SCOPE     = "https://cognitiveservices.azure.com/.default"
if not all([TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION]):
    raise RuntimeError("Missing AAD Speech env vars (TENANT_ID, CLIENT_ID, CLIENT_SECRET, SPEECH_REGION)")

cred = ClientSecretCredential(tenant_id=TENANT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)
def cog_token_str() -> str:
    tok = cred.get_token(COG_SCOPE).token
    return f"aad#{RESOURCE_ID}#{tok}" if RESOURCE_ID else tok

# ---- Voices (as requested)
VOICE_NEXUS  = os.getenv("AZURE_VOICE_HOST", "en-US-SaraNeural")   # Host (female, distinct)
VOICE_RECO   = os.getenv("AZURE_VOICE_BA",   "en-US-JennyNeural")  # Reco (female)
VOICE_STATIX = os.getenv("AZURE_VOICE_DA",   "en-US-BrianNeural")  # Statix (male)

VOICE_PLAN = {
    "NEXUS":{"style":"newscast-casual","base_pitch":"+2%","base_rate":"-3%"},
    "RECO":{"style":"friendly","base_pitch":"+1%","base_rate":"-4%"},
    "STATIX":{"style":"serious","base_pitch":"-2%","base_rate":"-5%"},
}

def _jitter(pct: str, spread=3) -> str:
    m = re.match(r'([+-]?\d+)%', pct.strip()); base = int(m.group(1)) if m else 0
    j = random.randint(-spread, spread)
    return f"{base+j}%"

def _emphasize_numbers(text: str) -> str:
    wrap = lambda s: f'<emphasis level="moderate">{s}</emphasis>'
    t = re.sub(r'\b\d{3,}(\.\d+)?\b', lambda m: wrap(m.group(0)), text)
    t = re.sub(r'\b-?\d+(\.\d+)?%\b', lambda m: wrap(m.group(0)), t)
    return t

def _clause_pauses(text: str) -> str:
    t = re.sub(r',\s*', ',<break time="220ms"/> ', text)
    t = re.sub(r';\s*', ';<break time="260ms"/> ', t)
    t = re.sub(r'\bHowever\b','However,<break time="220ms"/>', t, flags=re.I)
    t = re.sub(r'\bBut\b','But,<break time="220ms"/>', t, flags=re.I)
    return t

def _inflect(text: str, role: str) -> tuple[str,str]:
    base_pitch = VOICE_PLAN[role]["base_pitch"]
    base_rate  = VOICE_PLAN[role]["base_rate"]
    pitch = _jitter(base_pitch, 3)
    rate  = _jitter(base_rate, 2)
    if text.strip().endswith("?"):
        try:
            p = int(pitch.replace('%','')); pitch = f"{p+6}%"
        except: pitch = "+6%"
    elif re.search(r'\bhowever\b|\bbut\b', text, re.I):
        try:
            p = int(pitch.replace('%','')); pitch = f"{p-3}%"
        except: pitch = "-2%"
    return pitch, rate

def _ssml(voice: str, style: str|None, rate: str, pitch: str, inner: str) -> str:
    if style:
        return f"""<speak version="1.0" xml:lang="en-US"
  xmlns="http://www.w3.org/2001/10/synthesis"
  xmlns:mstts="http://www.w3.org/2001/mstts">
<voice name="{voice}">
  <mstts:express-as style="{style}">
    <prosody rate="{rate}" pitch="{pitch}">{inner}</prosody>
  </mstts:express-as>
</voice>
</speak>"""
    else:
        return f"""<speak version="1.0" xml:lang="en-US"
  xmlns="http://www.w3.org/2001/10/synthesis">
<voice name="{voice}">
  <prosody rate="{rate}" pitch="{pitch}">{inner}</prosody>
</voice>
</speak>"""

def text_to_ssml(text: str, role: str) -> str:
    plan = VOICE_PLAN[role]
    t = _emphasize_numbers(text.strip())
    t = _clause_pauses(t)
    t = f'{t}<break time="320ms"/>'
    pitch, rate = _inflect(text, role)
    voice = VOICE_NEXUS if role=="NEXUS" else VOICE_RECO if role=="RECO" else VOICE_STATIX
    return _ssml(voice, plan["style"], rate, pitch, t)

def synth(ssml: str) -> str:
    cfg = speechsdk.SpeechConfig(auth_token=cog_token_str(), region=SPEECH_REGION)
    cfg.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)
    fd, tmp = tempfile.mkstemp(prefix="seg_", suffix=".wav"); os.close(fd); TMP.append(tmp)
    out = speechsdk.audio.AudioOutputConfig(filename=tmp)
    spk = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=out)
    r = spk.speak_ssml_async(ssml).get()
    if r.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp
    # fallback once
    plain = re.sub(r'<[^>]+>',' ', ssml)
    spk = speechsdk.SpeechSynthesizer(speech_config=cfg, audio_config=out)
    r = spk.speak_text_async(plain).get()
    if r.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return tmp
    try: os.remove(tmp)
    except: pass
    raise RuntimeError("TTS failed")

def wav_len(path: str) -> float:
    with wave.open(path, "rb") as r:
        fr = r.getframerate() or 24000
        return r.getnframes()/float(fr)

def write_master(segments: list[str], out_path: str, rate=24000) -> str:
    fd, tmp = tempfile.mkstemp(prefix="final_", suffix=".wav"); os.close(fd)
    try:
        with wave.open(tmp, "wb") as w:
            w.setnchannels(1); w.setsampwidth(2); w.setframerate(rate)
            for seg in segments:
                with wave.open(seg, "rb") as r:
                    if (r.getframerate(), r.getnchannels(), r.getsampwidth()) != (rate,1,2):
                        raise RuntimeError(f"Segment format mismatch: {seg}")
                    w.writeframes(r.readframes(r.getnframes()))
        try: os.replace(tmp, out_path)
        except PermissionError:
            base,ext = os.path.splitext(out_path)
            alt = f"{base}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}{ext}"
            os.replace(tmp, alt)
            print(f"⚠️ Output was locked; wrote to {alt}")
            return alt
        return out_path
    except Exception:
        try: os.remove(tmp)
        except: pass
        raise

# ------------------------- file selection & context ------------------------
def list_json_files() -> list[str]:
    return [p.name for p in Path(".").iterdir() if p.is_file() and p.suffix.lower()==".json"]

def ask_files() -> str:
    files = list_json_files()
    print("JSON files in folder:", files)
    print("Type one of: data.json, metric_data.json, both, then Enter:")
    choice = (sys.stdin.readline() or "").strip().lower()
    if choice not in {"data.json","metric_data.json","both"}:
        if "data.json" in files and "metric_data.json" in files: return "both"
        return files[0] if files else "both"
    return choice

def load_context(choice: str) -> tuple[str, dict]:
    ctx, meta = "", {"files":[]}
    def add(fname: str):
        p = Path(fname)
        if p.exists():
            meta["files"].append(fname)
            return f"[{fname}]\n{p.read_text(encoding='utf-8', errors='ignore')}\n\n"
        return ""
    if choice=="both":
        ctx += add("data.json") + add("metric_data.json")
    else:
        ctx += add(choice)
    if not ctx: raise RuntimeError("No data found (need data.json and/or metric_data.json).")
    return ctx, meta

def ask_turns_and_duration() -> tuple[int,float]:
    print("Enter desired number of Reco/Statix turns (each turn = Reco then Statix). Press Enter for default 6:")
    t = (sys.stdin.readline() or "").strip()
    try: turns = int(t) if t else 6
    except: turns = 6
    turns = max(4, min(12, turns))
    print("Enter desired duration in minutes (2–5). Press Enter for default 3:")
    m = (sys.stdin.readline() or "").strip()
    try: mins = float(m) if m else 3.0
    except: mins = 3.0
    mins = max(2.0, min(5.0, mins))
    return turns, mins*60.0

# ------------------------- opener control / humanization -------------------
FORBIDDEN = {
    "RECO":{"absolutely","well","look","sure","okay","so","listen","hey","you know","hold on","right","great point"},
    "STATIX":{"hold on","actually","well","look","so","right","okay","absolutely","you know","listen","wait"},
}
OPENERS = {
    "RECO":[ "Given that","Looking at this","From that signal","On those figures","Based on the last month","If we take the trend","Against YTD context","From a planning view" ],
    "STATIX":[ "Data suggests","From the integrity check","The safer interpretation","Statistically speaking","Given the variance profile","From the control limits","Relative to seasonality","From the timestamp audit" ],
}
def strip_forbidden(text: str, role: str) -> str:
    low = text.strip().lower()
    for w in sorted(FORBIDDEN[role], key=lambda x: -len(x)):
        if low.startswith(w+" ") or low == w:
            return text[len(w):].lstrip(" ,.-–—")
    return text

def vary_opening(text: str, role: str, last_open: dict) -> str:
    t = strip_forbidden(text, role)
    first = (t.split()[:1] or [""])[0].strip(",. ").lower()
    if first in FORBIDDEN[role] or not first or random.random()<0.4:
        cand = random.choice(OPENERS[role])
        if last_open.get(role)==cand:
            pool = [c for c in OPENERS[role] if c!=cand]
            cand = random.choice(pool) if pool else cand
        last_open[role] = cand
        return f"{cand}, {t}"
    return t

def limit_sentence(text: str) -> str:
    return _one_sentence(text, max_words=26)

# ------------------------- AGENT PROMPTS (characters) ----------------------
SYSTEM_RECO = (
    "You are Agent Reco, a metrics recommendation specialist: pragmatic, collaborative, outcome-oriented. "
    "One sentence only (≈15–25 words), one idea, respond directly to Statix, cite datasets when helpful, "
    "recommend one concrete metric/action (rolling ASA, staffing ratio, control chart, timestamp audit, queue mapping, seasonality). "
    "Avoid filler; forbidden openers: Absolutely, Well, Look, Sure, Okay, So, Listen, Hey, You know, Hold on, Right, Great point. "
    "No lists/hashtags/file names; keep phrasing varied and human."
)
SYSTEM_STATIX = (
    "You are Agent Statix, the data quality/statistical integrity lead: precise, evidence-led, calm skeptic. "
    "One sentence only (≈15–25 words), one idea, respond to Reco, confirm or challenge with a specific data rationale "
    "(variance magnitudes, YTD deltas, 12-month range, WoW/MoM), add one integrity/trend check "
    "(timestamp audit, queue mapping, control limits, seasonality, winsorization). "
    "Avoid filler; forbidden openers: Hold on, Actually, Well, Look, So, Right, Okay, Absolutely, You know, Listen, Wait. "
    "No lists/hashtags/file names; keep phrasing varied and human."
)
SYSTEM_NEXUS = (
    "You are Agent Nexus, the warm, concise host. Your job: welcome listeners, set purpose, hand off/close cleanly. "
    "For generated lines, keep to 1 sentence (15–25 words)."
)

# ------------------------- FIXED LINES (verbatim) --------------------------
NEXUS_INTRO = (
    "Hello and welcome to Optum MultiAgent Conversation, where intelligence meets collaboration. I’m Agent Nexus, your host and guide through today’s episode. "
    "In this podcast, we bring together specialized agents to explore the world of metrics, data, and decision-making. Let’s meet today’s experts."
)
RECO_INTRO  = (
    "Hi everyone, I’m Agent Reco, your go-to for metric recommendations. I specialize in identifying the most impactful metrics for performance tracking, optimization, and strategic alignment."
)
STATIX_INTRO= (
    "Hello! I’m Agent Statix, focused on metric data. I dive deep into data sources, trends, and statistical integrity to ensure our metrics are not just smart—but solid."
)
NEXUS_OUTRO = "Thanking to Agents and listeners"

# ------------------------- MAIN -------------------------------------------
async def run_podcast():
    print("Starting Optum MultiAgent Conversation Podcast Generator (no music)…")
    choice = ask_files()
    context, meta = load_context(choice)
    turns, target_seconds = ask_turns_and_duration()

    out_dir = Path(f"podcast_output_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}")
    out_dir.mkdir(exist_ok=True)
    OUT_WAV    = str(out_dir / "podcast.wav")
    TRANS_JSON = str(out_dir / "transcript.jsonl")
    SCRIPT_TXT = str(out_dir / "script.txt")
    SHOW_NOTES = str(out_dir / "shownotes.md")

    # transcript log
    with open(TRANS_JSON, "w", encoding="utf-8") as _: pass
    transcript = []
    def log(role, text, tsec):
        with open(TRANS_JSON, "a", encoding="utf-8") as f:
            f.write(json.dumps({"ts":datetime.datetime.now().isoformat(),"t":round(tsec,2),"role":role,"text":text}, ensure_ascii=False)+"\n")
        transcript.append(f"{role}: {text}")

    segments, elapsed = [], 0.0

    # --- Fixed intros (no LLM)
    for line, role in [(NEXUS_INTRO,"NEXUS"), (RECO_INTRO,"RECO"), (STATIX_INTRO,"STATIX")]:
        ssml = text_to_ssml(line, role)
        wav  = synth(ssml); segments.append(wav); elapsed += wav_len(wav); log(f"Agent {role.title()}", line, elapsed)

    # --- Discussion
    seed = _soften("Use these datasets as primary context; keep a natural one-sentence discussion.\n"+context[:12000])
    last_line = seed
    last_open = {"RECO":None, "STATIX":None}

    for _ in range(turns):
        if elapsed >= target_seconds: break
        # RECO
        reco_raw  = await llm(SYSTEM_RECO, last_line, max_tokens=110, temperature=0.45)
        reco_line = limit_sentence(vary_opening(reco_raw, "RECO", last_open))
        ssml_r = text_to_ssml(reco_line, "RECO")
        wav_r  = synth(ssml_r); segments.append(wav_r); elapsed += wav_len(wav_r); log("Agent Reco", reco_line, elapsed)
        if elapsed >= target_seconds: break
        # STATIX
        statix_user = _soften(f"Agent Reco just said: {reco_line}\nReference context (no need to name files):\n{context[:9000]}")
        statix_raw  = await llm(SYSTEM_STATIX, statix_user, max_tokens=110, temperature=0.45)
        statix_line = limit_sentence(vary_opening(statix_raw, "STATIX", last_open))
        ssml_s = text_to_ssml(statix_line, "STATIX")
        wav_s  = synth(ssml_s); segments.append(wav_s); elapsed += wav_len(wav_s); log("Agent Statix", statix_line, elapsed)
        last_line = statix_line

    # --- Fixed outro (no LLM)
    ssml_out = text_to_ssml(NEXUS_OUTRO, "NEXUS")
    wav_out  = synth(ssml_out); segments.append(wav_out); elapsed += wav_len(wav_out); log("Agent Nexus", NEXUS_OUTRO, elapsed)

    # atomic render
    written = write_master(segments, OUT_WAV)

    # save texts (no console spam)
    with open(SCRIPT_TXT,"w",encoding="utf-8") as f: f.write("\n".join(transcript))
    with open(SHOW_NOTES,"w",encoding="utf-8") as f:
        f.write("# Optum MultiAgent Conversation\n")
        f.write(f"- Recorded: {datetime.datetime.now().isoformat()}\n")
        f.write(f"- Duration: ~{int(elapsed)}s\n")
        f.write(f"- Files used: {', '.join(meta['files'])}\n")
        f.write("\n## Format\n- Fixed host/panel intros (no music)\n- One-sentence Reco/Statix rounds\n- Fixed host outro\n")
        f.write("\n## Voice Map\n- Nexus: " + VOICE_NEXUS + "\n- Reco: " + VOICE_RECO + "\n- Statix: " + VOICE_STATIX + "\n")

    # best-effort temp cleanup
    for p in list(TMP):
        try:
            if os.path.exists(p): os.remove(p)
        except Exception: pass

    print(f"Saved: {written}")
    print(f"Extra: {SCRIPT_TXT}, {SHOW_NOTES}, {TRANS_JSON}")

# ------------------------- entry ------------------------------------------
if __name__ == "__main__":
    try:
        asyncio.run(run_podcast())
    except Exception as e:
        print(f"X Error: {e}")
        import traceback; traceback.print_exc()
